{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5a4e7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install evaluate\n",
    "# !pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f80a77bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install accelerate -U\n",
    "# !pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1dcf3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, 'C:/Users/fschr/Desktop/Masterarbeit/master-thesis-software-ie/experiments')\n",
    "import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa672907",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb00278",
   "metadata": {},
   "source": [
    "## Read the Dataset (Sentences and Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0801d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/subtask2/subtask2_train.data.txt', 'r', encoding='utf-8') as file:\n",
    "    sentences = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f74eeafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/subtask2/subtask2_train.labels.txt', 'r', encoding='utf-8') as file:\n",
    "    labels = file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6625f0bd",
   "metadata": {},
   "source": [
    "## Convert the Datasets into a pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53a1418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.DataFrame(list(zip(sentences, labels)), columns=['sentences', 'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a1a271",
   "metadata": {},
   "source": [
    "## Split Sentences and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "927cddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['sentences'] = dataset['sentences'].apply(lambda row:row.split())\n",
    "dataset['labels'] = dataset['labels'].apply(lambda row:row.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d364cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Here, we, report, a, comprehensive, suite, fo...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The, resource, is, available, free, of, charg...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, B-URL, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[In, this, work, ,, we, described, the, DelPhi...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\", Project, name, :, DelPhi, Project, home, p...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-URL, O, O, O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[We, have, developed, ANDES, ,, a, software, l...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  \\\n",
       "0  [Here, we, report, a, comprehensive, suite, fo...   \n",
       "1  [The, resource, is, available, free, of, charg...   \n",
       "2  [In, this, work, ,, we, described, the, DelPhi...   \n",
       "3  [\", Project, name, :, DelPhi, Project, home, p...   \n",
       "4  [We, have, developed, ANDES, ,, a, software, l...   \n",
       "\n",
       "                                              labels  \n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  \n",
       "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, B-URL, O]  \n",
       "2            [O, O, O, O, O, O, O, O, O, O, O, O, O]  \n",
       "3  [O, O, O, O, O, O, O, O, O, O, B-URL, O, O, O,...  \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb23abf2",
   "metadata": {},
   "source": [
    "## The class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f63ea35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-URL',\n",
       " 'B-AlternativeName',\n",
       " 'I-AlternativeName',\n",
       " 'B-License',\n",
       " 'I-License',\n",
       " 'B-Version',\n",
       " 'B-Abbreviation',\n",
       " 'B-Citation',\n",
       " 'B-Release',\n",
       " 'B-Developer',\n",
       " 'I-Developer',\n",
       " 'I-Citation',\n",
       " 'B-Extension',\n",
       " 'I-Extension',\n",
       " 'I-Version',\n",
       " 'I-URL',\n",
       " 'I-Release']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_labels = []\n",
    "for line in labels:\n",
    "    labels_list = line.split()\n",
    "    for label in labels_list:\n",
    "        if label not in class_labels:\n",
    "            class_labels.append(label)\n",
    "            \n",
    "class_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8285c24f",
   "metadata": {},
   "source": [
    "### Entity Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce2cac17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-URL',\n",
       " 'B-AlternativeName',\n",
       " 'I-AlternativeName',\n",
       " 'B-License',\n",
       " 'I-License',\n",
       " 'B-Version',\n",
       " 'B-Abbreviation',\n",
       " 'B-Citation',\n",
       " 'B-Release',\n",
       " 'B-Developer',\n",
       " 'I-Developer',\n",
       " 'I-Citation',\n",
       " 'B-Extension',\n",
       " 'I-Extension',\n",
       " 'I-Version',\n",
       " 'I-URL',\n",
       " 'I-Release']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_labels = ['O']\n",
    "for label in class_labels:\n",
    "    if label == 'O':\n",
    "        continue\n",
    "    entity_label = label.split('_')[0]\n",
    "    if entity_label not in entity_labels:\n",
    "        entity_labels.append(entity_label)\n",
    "\n",
    "entity_label_grouping = True\n",
    "entity_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ac049e",
   "metadata": {},
   "source": [
    "### Change the labels, if we have Entity Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8da21af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if entity_label_grouping:\n",
    "    dataset['labels'] = dataset['labels'].apply(helper.reduce_to_entity_type_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1eefb3",
   "metadata": {},
   "source": [
    "### Label to ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "021193d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if entity_label_grouping:\n",
    "    class_labels = entity_labels\n",
    "label_to_id = {label:id for id, label in enumerate(class_labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67025ee",
   "metadata": {},
   "source": [
    "### ID to Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd384b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_label = {id:label for id, label in enumerate(class_labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19497097",
   "metadata": {},
   "source": [
    "## Map Labels to Class_Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b30533a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['ids'] = dataset['labels'].apply(lambda row: [label_to_id.get(label) for label in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a08d515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>labels</th>\n",
       "      <th>ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Here, we, report, a, comprehensive, suite, fo...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[The, resource, is, available, free, of, charg...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, B-URL, O]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[In, this, work, ,, we, described, the, DelPhi...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\", Project, name, :, DelPhi, Project, home, p...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-URL, O, O, O,...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[We, have, developed, ANDES, ,, a, software, l...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentences  \\\n",
       "0  [Here, we, report, a, comprehensive, suite, fo...   \n",
       "1  [The, resource, is, available, free, of, charg...   \n",
       "2  [In, this, work, ,, we, described, the, DelPhi...   \n",
       "3  [\", Project, name, :, DelPhi, Project, home, p...   \n",
       "4  [We, have, developed, ANDES, ,, a, software, l...   \n",
       "\n",
       "                                              labels  \\\n",
       "0  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, B-URL, O]   \n",
       "2            [O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "3  [O, O, O, O, O, O, O, O, O, O, B-URL, O, O, O,...   \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                                 ids  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]  \n",
       "2            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ...  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b65b599",
   "metadata": {},
   "source": [
    "## Prepare and Train the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092ecf10",
   "metadata": {},
   "source": [
    "### Split the dataset into Trian and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4e9236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, validation = train_test_split(dataset, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e346c762",
   "metadata": {},
   "source": [
    "### Write the Train and Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5a7129ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('../../data/subtask2/subtask2_split.train.txt', header=False, index=False, sep='\\n', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff7917c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation.to_csv('../../data/subtask2/subtask2_split.validation.txt', header=False, index=False, sep='\\n', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737508fe",
   "metadata": {},
   "source": [
    "## Tokenize and convert the labels from tokenized into ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6fc6d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, AutoTokenizer\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16c92d5",
   "metadata": {},
   "source": [
    "## Positive Samples (Sentences with labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a39c136",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_contains_labels = train.ids.apply(sum) != 0\n",
    "validation_contains_labels = validation.ids.apply(sum) != 0\n",
    "\n",
    "reduce_to_positive_samples = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3277a123",
   "metadata": {},
   "source": [
    "## Negative Samples (Sentences without any labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b87a2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_without_labels = train.ids.apply(sum) == 0\n",
    "validation_without_labels = validation.ids.apply(sum) == 0\n",
    "\n",
    "reduce_to_negative_samples = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6af66e2",
   "metadata": {},
   "source": [
    "## Reduce the dataset to positive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "35db7aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reduce_to_positive_samples:\n",
    "    train = train[train_contains_labels].copy()\n",
    "    validation = validation[validation_contains_labels].copy()\n",
    "elif reduce_to_negative_samples:\n",
    "    train = train[train_without_labels].copy()\n",
    "    validation = validation[validation_without_labels].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c1e044",
   "metadata": {},
   "source": [
    "## Tokenize and convert the labels from tokenized into ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85394b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(input_data):\n",
    "    tokenized_train_inputs = tokenizer(\n",
    "        input_data,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "    )\n",
    "    \n",
    "    return tokenized_train_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13b02ac",
   "metadata": {},
   "source": [
    "### Tokenize Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e7ad7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tokenized'] = train.apply(lambda row: helper.tokenized_align_labels(tokenization(row['sentences']), row['ids']), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974aae82",
   "metadata": {},
   "source": [
    "### Tokenize Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b31d465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation['tokenized'] = validation.apply(lambda row: helper.tokenized_align_labels(tokenization(row['sentences']), row['ids']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc580e9",
   "metadata": {},
   "source": [
    "## Prepare Train Dataset for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85795645",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_dataset = train.tokenized.apply(\n",
    "    lambda x: {\n",
    "        k: v[0]\n",
    "        if type(v) is not list\n",
    "        else torch.tensor(v)\n",
    "        for k, v in x.items()}).to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5a6ed8",
   "metadata": {},
   "source": [
    "## Prepare Train Dataset for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80168a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Val_dataset = validation.tokenized.apply(\n",
    "    lambda x: {\n",
    "        k: v[0]\n",
    "        if type(v) is not list\n",
    "        else torch.tensor(v)\n",
    "        for k, v in x.items()}).to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200c7470",
   "metadata": {},
   "source": [
    "## Load Pre_trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9eb6b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "### todo guck mal nach cased und uncased ob es mit cased besser funktioniert oder mit uncased\n",
    "model = AutoModelForTokenClassification.from_pretrained('bert-base-uncased', id2label=id_to_label, num_labels=len(class_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bbd044",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2903731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "metric = evaluate.load('seqeval')\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds, label_class=class_labels):\n",
    "    logits, labels = eval_preds\n",
    "    # becase the logics and probabilities both are in the same order, we don't need to aply softmax here\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    # now we need to remove all the values, where the label is -100\n",
    "    # before passing to metric.compute we should have these inputs as a list\n",
    "    true_labels = [[label_class[l] for l in label if l != -100]\n",
    "                   for label in labels]\n",
    "\n",
    "    true_predictions = [[label_class[p] for p,l in zip(prediction, label) if l != -100]\n",
    "                        for prediction, label in zip(predictions, labels)]\n",
    "\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    return all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dff1826",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78677e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/39 24:39, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>Citation</th>\n",
       "      <th>Developer</th>\n",
       "      <th>Extension</th>\n",
       "      <th>License</th>\n",
       "      <th>Release</th>\n",
       "      <th>Url</th>\n",
       "      <th>Version</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.472182</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 22}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 28}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 3}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 12}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 53}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.937388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.355920</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 22}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 28}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 3}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 12}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 53}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.937388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.330088</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 22}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 28}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 3}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 12}</td>\n",
       "      <td>{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 53}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.937388</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fschr\\AppData\\Roaming\\Python\\Python311\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\fschr\\AppData\\Roaming\\Python\\Python311\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/Abbreviation\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 22}\" of type <class 'dict'> for key \"eval/Citation\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 28}\" of type <class 'dict'> for key \"eval/Developer\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/Extension\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1}\" of type <class 'dict'> for key \"eval/License\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 3}\" of type <class 'dict'> for key \"eval/Release\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 12}\" of type <class 'dict'> for key \"eval/URL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 53}\" of type <class 'dict'> for key \"eval/Version\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/Abbreviation\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 22}\" of type <class 'dict'> for key \"eval/Citation\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 28}\" of type <class 'dict'> for key \"eval/Developer\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/Extension\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1}\" of type <class 'dict'> for key \"eval/License\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 3}\" of type <class 'dict'> for key \"eval/Release\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 12}\" of type <class 'dict'> for key \"eval/URL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 53}\" of type <class 'dict'> for key \"eval/Version\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/Abbreviation\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 22}\" of type <class 'dict'> for key \"eval/Citation\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 28}\" of type <class 'dict'> for key \"eval/Developer\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 2}\" of type <class 'dict'> for key \"eval/Extension\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 1}\" of type <class 'dict'> for key \"eval/License\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 3}\" of type <class 'dict'> for key \"eval/Release\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 12}\" of type <class 'dict'> for key \"eval/URL\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 53}\" of type <class 'dict'> for key \"eval/Version\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"
     ]
    }
   ],
   "source": [
    "from transformers import  TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir='../../data/subtask2/sub_ner',\n",
    "                                  num_train_epochs=3,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=8,\n",
    "                                  per_device_eval_batch_size=8,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy='epoch',\n",
    "                                  disable_tqdm=False)\n",
    "\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, compute_metrics=compute_metrics, train_dataset=Train_dataset,\n",
    "                  eval_dataset=Val_dataset,tokenizer=tokenizer)\n",
    "\n",
    "\n",
    "dataset_performance = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f54ac57",
   "metadata": {},
   "source": [
    "## Performance of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42725bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=39, training_loss=0.8326547084710537, metrics={'train_runtime': 1506.685, 'train_samples_per_second': 0.199, 'train_steps_per_second': 0.026, 'total_flos': 78400366387200.0, 'train_loss': 0.8326547084710537, 'epoch': 3.0})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20e6a97",
   "metadata": {},
   "source": [
    "## Save the fine-tuned Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e563815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../../data/subtask2/dataset_tokenizer\\\\tokenizer_config.json',\n",
       " '../../data/subtask2/dataset_tokenizer\\\\special_tokens_map.json',\n",
       " '../../data/subtask2/dataset_tokenizer\\\\vocab.txt',\n",
       " '../../data/subtask2/dataset_tokenizer\\\\added_tokens.json',\n",
       " '../../data/subtask2/dataset_tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"../../data/subtask2/dataset_ner_model\")\n",
    "tokenizer.save_pretrained(\"../../data/subtask2/dataset_tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8e23bd",
   "metadata": {},
   "source": [
    "## Read the Test dataset and Prediction for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b7d6fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/subtask2/subtask2_test.data.txt', 'r', encoding='utf-8') as file:\n",
    "    test = file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0905d60",
   "metadata": {},
   "source": [
    "## Post-process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5d1d62",
   "metadata": {},
   "source": [
    "### convert ids to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "210fe7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def convert_ids_to_labels(sentence, model, tokenizer, id_to_label=id_to_label):\n",
    "      sentence = sentence.split()\n",
    "      inputs = tokenizer([sentence], truncation=True,is_split_into_words = True, padding=True,return_tensors='pt')\n",
    "      word_ids = inputs.word_ids()\n",
    "      with torch.no_grad():\n",
    "          model.eval()\n",
    "          outputs = model(**inputs)\n",
    "      prediction = outputs.logits.argmax(dim=2)\n",
    "      prediction = prediction[0].tolist()\n",
    "      predictions_for_words = helper.align_labels(word_ids, prediction)\n",
    "      predicted_labels = [id_to_label[id] for id in predictions_for_words]\n",
    "      labels = ' '.join([p_label for p_label in predicted_labels]) ### Todo guck mal ob du überhaupt hier die str brauchst\n",
    "      return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf152a98",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9f66d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predicted_entities_dataset = []\n",
    "for sentence in test:\n",
    "    labels = convert_ids_to_labels(sentence=sentence, model=model, tokenizer=tokenizer, id_to_label=id_to_label)\n",
    "    all_predicted_entities_dataset.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb815407",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/subtask2/prediction/prediction_dataset.txt', 'w') as file:\n",
    "  for prediction in all_predicted_entities_dataset:\n",
    "    file.write(f'{prediction}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b133d6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
