{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "bf7c50a1",
      "metadata": {
        "id": "bf7c50a1"
      },
      "outputs": [],
      "source": [
        "# !pip install evaluate\n",
        "# !pip install seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "758df96a",
      "metadata": {
        "id": "758df96a"
      },
      "outputs": [],
      "source": [
        "# !pip install accelerate -U\n",
        "# !pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "39f53ac2",
      "metadata": {
        "id": "39f53ac2"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "from helper import align_labels\n",
        "import helper\n",
        "import collections"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b90a759",
      "metadata": {
        "id": "2b90a759"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe05fad7",
      "metadata": {
        "id": "fe05fad7"
      },
      "source": [
        "### Read the Train Dataset (Sentences and Labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "37d746ab",
      "metadata": {
        "id": "37d746ab"
      },
      "outputs": [],
      "source": [
        "# Open the Data of Sentences\n",
        "with open('subtask2_train.data.txt', 'r', encoding='utf-8') as file:\n",
        "    sentences = file.readlines()\n",
        "\n",
        "\n",
        "# Open the label data\n",
        "with open('subtask2_train.labels.txt', 'r', encoding='utf-8') as file:\n",
        "    labels = file.readlines()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b31503f",
      "metadata": {
        "id": "8b31503f"
      },
      "source": [
        "### Convert the Dataset into a pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f73c1764",
      "metadata": {
        "id": "f73c1764"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset = pd.DataFrame(list(zip(sentences, labels)), columns=['sentences', 'labels'])\n",
        "# split sentences and labels\n",
        "dataset['sentences'] = dataset['sentences'].apply(lambda row: row.split())\n",
        "dataset['labels'] = dataset['labels'].apply(lambda row: row.split())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "705dee45",
      "metadata": {
        "id": "705dee45"
      },
      "source": [
        "### Unique labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "55e40869",
      "metadata": {
        "id": "55e40869"
      },
      "outputs": [],
      "source": [
        "unique_labels = []\n",
        "\n",
        "for line in labels:\n",
        "    labels_list = line.split()\n",
        "    for label in labels_list:\n",
        "        if label not in unique_labels:\n",
        "            unique_labels.append(label)\n",
        "\n",
        "uniqueLabel_to_ID = {unique_label: ID for ID, unique_label in enumerate(unique_labels)}\n",
        "ID_to_uniqueLable = {ID: unique_label for ID, unique_label in enumerate(unique_labels)}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2b51fd7",
      "metadata": {
        "id": "a2b51fd7"
      },
      "source": [
        "### Map each label to its ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cf0175c6",
      "metadata": {
        "id": "cf0175c6"
      },
      "outputs": [],
      "source": [
        "dataset['IDs'] = dataset['labels'].apply(lambda row: [uniqueLabel_to_ID.get(label) for label in row])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d90f934",
      "metadata": {
        "id": "3d90f934"
      },
      "source": [
        "# Prepare the train and validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e69a8d90",
      "metadata": {
        "id": "e69a8d90"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, validation = train_test_split(dataset, test_size=0.25, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "386fba33",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "386fba33",
        "outputId": "b02f12e1-f62b-4f39-d195-c38d4879c066"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1764, 589)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "len(train), len(validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a6b5fdb",
      "metadata": {
        "id": "7a6b5fdb"
      },
      "source": [
        "## Tokenize and convet the labels from tokenized into IDs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "c89d626c",
      "metadata": {
        "id": "c89d626c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c965d587-e97a-42bf-d17a-5ed54ac42885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizerFast, AutoTokenizer\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8606e14f",
      "metadata": {
        "id": "8606e14f"
      },
      "outputs": [],
      "source": [
        "def tokenization(input_data):\n",
        "    tokenized_train_inputs = tokenizer(\n",
        "        input_data,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        is_split_into_words=True,\n",
        "        padding=\"do_not_pad\",\n",
        "        max_length=512,\n",
        "    )\n",
        "\n",
        "    return tokenized_train_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e31364e4",
      "metadata": {
        "id": "e31364e4"
      },
      "source": [
        "### Trian Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "72213206",
      "metadata": {
        "id": "72213206"
      },
      "outputs": [],
      "source": [
        "train['tokenized'] = train.apply(lambda row: helper.tokenized_align_labels(tokenization(row['sentences']), row['IDs']), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "396ed37d",
      "metadata": {
        "id": "396ed37d"
      },
      "source": [
        "### Validation Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "7f6feb5c",
      "metadata": {
        "id": "7f6feb5c"
      },
      "outputs": [],
      "source": [
        "validation['tokenized'] = validation.apply(lambda row: helper.tokenized_align_labels(tokenization(row['sentences']), row['IDs']), axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88df74cf",
      "metadata": {
        "id": "88df74cf"
      },
      "source": [
        "### Prepare Train dataset for fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "59ea303b",
      "metadata": {
        "id": "59ea303b"
      },
      "outputs": [],
      "source": [
        "Train_dataset = train.tokenized.apply(\n",
        "    lambda x: {\n",
        "        k: v[0]\n",
        "        if type(v) is not list\n",
        "        else torch.tensor(v)\n",
        "        for k, v in x.items()}).to_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e905af2",
      "metadata": {
        "id": "0e905af2"
      },
      "source": [
        "### Prepare validation dataset for fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "eb067a14",
      "metadata": {
        "id": "eb067a14"
      },
      "outputs": [],
      "source": [
        "Val_dataset = validation.tokenized.apply(\n",
        "    lambda x: {\n",
        "        k: v[0]\n",
        "        if type(v) is not list\n",
        "        else torch.tensor(v)\n",
        "        for k, v in x.items()}).to_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6b02cde",
      "metadata": {
        "id": "d6b02cde"
      },
      "source": [
        "## Load pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "defb4af7",
      "metadata": {
        "id": "defb4af7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7063b74-70bb-4ed6-83de-b787c63650eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "### todo guck mal nach cased und uncased ob es mit cased besser funktioniert oder mit uncased\n",
        "model_name = \"bert-base-uncased\"\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name, id2label=ID_to_uniqueLable, num_labels=len(unique_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0eccd175",
      "metadata": {
        "id": "0eccd175"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "96ca025b",
      "metadata": {
        "id": "96ca025b"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "metric = evaluate.load('seqeval')\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds, label_class=unique_labels):\n",
        "    logits, labels = eval_preds\n",
        "    # becase the logics and probabilities both are in the same order, we don't need to aply softmax here\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    # now we need to remove all the values, where the label is -100\n",
        "    # before passing to metric.compute we should have these inputs as a list\n",
        "    true_labels = [[label_class[l] for l in label if l != -100]\n",
        "                   for label in labels]\n",
        "\n",
        "    true_predictions = [[label_class[p] for p,l in zip(prediction, label) if l != -100]\n",
        "                        for prediction, label in zip(predictions, labels)]\n",
        "\n",
        "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels, zero_division=0)\n",
        "    support_all = 0\n",
        "    f1_weighted = {}\n",
        "    label_values = {}\n",
        "    entity_labels = list({l[2:] for l in label_class if l != 'O'})\n",
        "    for label in entity_labels:\n",
        "      label_metrics = all_metrics.get(label, dict())\n",
        "      for metric_label, value in label_metrics.items():\n",
        "        if metric_label == 'number':\n",
        "          support_all += value\n",
        "        if metric_label == 'f1':\n",
        "          f1_weighted[label] = value * label_metrics['number']\n",
        "        label_values[f\"{metric_label}_{label}\"] = value\n",
        "      if label_metrics:\n",
        "        del all_metrics[label]\n",
        "    f1_macro_weighted = 0.\n",
        "    if support_all != 0:\n",
        "      for f1 in f1_weighted.values():\n",
        "        f1_macro_weighted += f1 / support_all\n",
        "    all_metrics[f\"f1_macro_weighted\"] = f1_macro_weighted\n",
        "    all_metrics |= label_values\n",
        "    return all_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56d0c795",
      "metadata": {
        "id": "56d0c795"
      },
      "source": [
        "# Parameter optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "209b4afc",
      "metadata": {
        "id": "209b4afc"
      },
      "source": [
        "## Define, perform the hyperparameter search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "049c1545",
      "metadata": {
        "id": "049c1545"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers optuna datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ac3d6c9",
      "metadata": {
        "id": "5ac3d6c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a3e1ba4e-4903-4158-e31d-7dede961f25f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-16 10:49:33,407] A new study created in memory with name: no-name-260f22a8-439e-47c8-8d9f-2925842f12bb\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='165' max='165' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [165/165 01:34, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Overall Precision</th>\n",
              "      <th>Overall Recall</th>\n",
              "      <th>Overall F1</th>\n",
              "      <th>Overall Accuracy</th>\n",
              "      <th>F1 Macro Weighted</th>\n",
              "      <th>Precision Version</th>\n",
              "      <th>Recall Version</th>\n",
              "      <th>F1 Version</th>\n",
              "      <th>Number Version</th>\n",
              "      <th>Precision Alternativename</th>\n",
              "      <th>Recall Alternativename</th>\n",
              "      <th>F1 Alternativename</th>\n",
              "      <th>Number Alternativename</th>\n",
              "      <th>Precision Extension</th>\n",
              "      <th>Recall Extension</th>\n",
              "      <th>F1 Extension</th>\n",
              "      <th>Number Extension</th>\n",
              "      <th>Precision Citation</th>\n",
              "      <th>Recall Citation</th>\n",
              "      <th>F1 Citation</th>\n",
              "      <th>Number Citation</th>\n",
              "      <th>Precision License</th>\n",
              "      <th>Recall License</th>\n",
              "      <th>F1 License</th>\n",
              "      <th>Number License</th>\n",
              "      <th>Precision Developer</th>\n",
              "      <th>Recall Developer</th>\n",
              "      <th>F1 Developer</th>\n",
              "      <th>Number Developer</th>\n",
              "      <th>Precision Release</th>\n",
              "      <th>Recall Release</th>\n",
              "      <th>F1 Release</th>\n",
              "      <th>Number Release</th>\n",
              "      <th>Precision Url</th>\n",
              "      <th>Recall Url</th>\n",
              "      <th>F1 Url</th>\n",
              "      <th>Number Url</th>\n",
              "      <th>Precision Abbreviation</th>\n",
              "      <th>Recall Abbreviation</th>\n",
              "      <th>F1 Abbreviation</th>\n",
              "      <th>Number Abbreviation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.142776</td>\n",
              "      <td>0.745736</td>\n",
              "      <td>0.677465</td>\n",
              "      <td>0.709963</td>\n",
              "      <td>0.969494</td>\n",
              "      <td>0.645675</td>\n",
              "      <td>0.884488</td>\n",
              "      <td>0.940351</td>\n",
              "      <td>0.911565</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.696629</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>0.805195</td>\n",
              "      <td>130</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.162791</td>\n",
              "      <td>0.090323</td>\n",
              "      <td>0.116183</td>\n",
              "      <td>155</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16</td>\n",
              "      <td>0.961538</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.949367</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.533500</td>\n",
              "      <td>0.072795</td>\n",
              "      <td>0.791557</td>\n",
              "      <td>0.845070</td>\n",
              "      <td>0.817439</td>\n",
              "      <td>0.981672</td>\n",
              "      <td>0.788755</td>\n",
              "      <td>0.873016</td>\n",
              "      <td>0.964912</td>\n",
              "      <td>0.916667</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.767123</td>\n",
              "      <td>0.861538</td>\n",
              "      <td>0.811594</td>\n",
              "      <td>130</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.649038</td>\n",
              "      <td>0.870968</td>\n",
              "      <td>0.743802</td>\n",
              "      <td>155</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.125000</td>\n",
              "      <td>0.210526</td>\n",
              "      <td>16</td>\n",
              "      <td>0.915663</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.932515</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [37/37 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-16 10:51:14,671] Trial 0 finished with value: 0.7887551417206412 and parameters: {'learning_rate': 2.4612471273961025e-05, 'batch_size': 16, 'num_train_epochs': 3, 'weight_decay': 2.61958694318397e-05}. Best is trial 0 with value: 0.7887551417206412.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='550' max='550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [550/550 02:49, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Overall Precision</th>\n",
              "      <th>Overall Recall</th>\n",
              "      <th>Overall F1</th>\n",
              "      <th>Overall Accuracy</th>\n",
              "      <th>F1 Macro Weighted</th>\n",
              "      <th>Precision Version</th>\n",
              "      <th>Recall Version</th>\n",
              "      <th>F1 Version</th>\n",
              "      <th>Number Version</th>\n",
              "      <th>Precision Alternativename</th>\n",
              "      <th>Recall Alternativename</th>\n",
              "      <th>F1 Alternativename</th>\n",
              "      <th>Number Alternativename</th>\n",
              "      <th>Precision Extension</th>\n",
              "      <th>Recall Extension</th>\n",
              "      <th>F1 Extension</th>\n",
              "      <th>Number Extension</th>\n",
              "      <th>Precision Citation</th>\n",
              "      <th>Recall Citation</th>\n",
              "      <th>F1 Citation</th>\n",
              "      <th>Number Citation</th>\n",
              "      <th>Precision License</th>\n",
              "      <th>Recall License</th>\n",
              "      <th>F1 License</th>\n",
              "      <th>Number License</th>\n",
              "      <th>Precision Developer</th>\n",
              "      <th>Recall Developer</th>\n",
              "      <th>F1 Developer</th>\n",
              "      <th>Number Developer</th>\n",
              "      <th>Precision Release</th>\n",
              "      <th>Recall Release</th>\n",
              "      <th>F1 Release</th>\n",
              "      <th>Number Release</th>\n",
              "      <th>Precision Url</th>\n",
              "      <th>Recall Url</th>\n",
              "      <th>F1 Url</th>\n",
              "      <th>Number Url</th>\n",
              "      <th>Precision Abbreviation</th>\n",
              "      <th>Recall Abbreviation</th>\n",
              "      <th>F1 Abbreviation</th>\n",
              "      <th>Number Abbreviation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.118800</td>\n",
              "      <td>0.140258</td>\n",
              "      <td>0.739264</td>\n",
              "      <td>0.678873</td>\n",
              "      <td>0.707783</td>\n",
              "      <td>0.970724</td>\n",
              "      <td>0.645753</td>\n",
              "      <td>0.887417</td>\n",
              "      <td>0.940351</td>\n",
              "      <td>0.913118</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.696629</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>0.805195</td>\n",
              "      <td>130</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.152174</td>\n",
              "      <td>0.090323</td>\n",
              "      <td>0.113360</td>\n",
              "      <td>155</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.071100</td>\n",
              "      <td>0.063725</td>\n",
              "      <td>0.827397</td>\n",
              "      <td>0.850704</td>\n",
              "      <td>0.838889</td>\n",
              "      <td>0.983701</td>\n",
              "      <td>0.816993</td>\n",
              "      <td>0.895425</td>\n",
              "      <td>0.961404</td>\n",
              "      <td>0.927242</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.805970</td>\n",
              "      <td>0.830769</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>130</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.710526</td>\n",
              "      <td>0.870968</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>155</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>16</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.046500</td>\n",
              "      <td>0.057103</td>\n",
              "      <td>0.797665</td>\n",
              "      <td>0.866197</td>\n",
              "      <td>0.830520</td>\n",
              "      <td>0.985731</td>\n",
              "      <td>0.818275</td>\n",
              "      <td>0.901316</td>\n",
              "      <td>0.961404</td>\n",
              "      <td>0.930390</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.793103</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>0.836364</td>\n",
              "      <td>130</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>9</td>\n",
              "      <td>0.700508</td>\n",
              "      <td>0.890323</td>\n",
              "      <td>0.784091</td>\n",
              "      <td>155</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.439024</td>\n",
              "      <td>16</td>\n",
              "      <td>0.938272</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.944099</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [74/74 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-16 10:54:10,085] Trial 1 finished with value: 0.8182746401597264 and parameters: {'learning_rate': 1.109728005766158e-05, 'batch_size': 8, 'num_train_epochs': 5, 'weight_decay': 0.00039908643992766346}. Best is trial 1 with value: 0.8182746401597264.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='168' max='168' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [168/168 03:31, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Overall Precision</th>\n",
              "      <th>Overall Recall</th>\n",
              "      <th>Overall F1</th>\n",
              "      <th>Overall Accuracy</th>\n",
              "      <th>F1 Macro Weighted</th>\n",
              "      <th>Precision Version</th>\n",
              "      <th>Recall Version</th>\n",
              "      <th>F1 Version</th>\n",
              "      <th>Number Version</th>\n",
              "      <th>Precision Alternativename</th>\n",
              "      <th>Recall Alternativename</th>\n",
              "      <th>F1 Alternativename</th>\n",
              "      <th>Number Alternativename</th>\n",
              "      <th>Precision Extension</th>\n",
              "      <th>Recall Extension</th>\n",
              "      <th>F1 Extension</th>\n",
              "      <th>Number Extension</th>\n",
              "      <th>Precision Citation</th>\n",
              "      <th>Recall Citation</th>\n",
              "      <th>F1 Citation</th>\n",
              "      <th>Number Citation</th>\n",
              "      <th>Precision License</th>\n",
              "      <th>Recall License</th>\n",
              "      <th>F1 License</th>\n",
              "      <th>Number License</th>\n",
              "      <th>Precision Developer</th>\n",
              "      <th>Recall Developer</th>\n",
              "      <th>F1 Developer</th>\n",
              "      <th>Number Developer</th>\n",
              "      <th>Precision Release</th>\n",
              "      <th>Recall Release</th>\n",
              "      <th>F1 Release</th>\n",
              "      <th>Number Release</th>\n",
              "      <th>Precision Url</th>\n",
              "      <th>Recall Url</th>\n",
              "      <th>F1 Url</th>\n",
              "      <th>Number Url</th>\n",
              "      <th>Precision Abbreviation</th>\n",
              "      <th>Recall Abbreviation</th>\n",
              "      <th>F1 Abbreviation</th>\n",
              "      <th>Number Abbreviation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.390714</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.937696</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>130</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>155</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.209578</td>\n",
              "      <td>0.912773</td>\n",
              "      <td>0.412676</td>\n",
              "      <td>0.568380</td>\n",
              "      <td>0.955040</td>\n",
              "      <td>0.456212</td>\n",
              "      <td>0.937255</td>\n",
              "      <td>0.838596</td>\n",
              "      <td>0.885185</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.415385</td>\n",
              "      <td>0.551020</td>\n",
              "      <td>130</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>155</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.126078</td>\n",
              "      <td>0.742900</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.720812</td>\n",
              "      <td>0.973000</td>\n",
              "      <td>0.680293</td>\n",
              "      <td>0.873377</td>\n",
              "      <td>0.943860</td>\n",
              "      <td>0.907251</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.713333</td>\n",
              "      <td>0.823077</td>\n",
              "      <td>0.764286</td>\n",
              "      <td>130</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.340909</td>\n",
              "      <td>0.290323</td>\n",
              "      <td>0.313589</td>\n",
              "      <td>155</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16</td>\n",
              "      <td>0.962025</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.955975</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.099226</td>\n",
              "      <td>0.774366</td>\n",
              "      <td>0.816901</td>\n",
              "      <td>0.795065</td>\n",
              "      <td>0.979581</td>\n",
              "      <td>0.762945</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.957895</td>\n",
              "      <td>0.910000</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.732026</td>\n",
              "      <td>0.861538</td>\n",
              "      <td>0.791519</td>\n",
              "      <td>130</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.595000</td>\n",
              "      <td>0.767742</td>\n",
              "      <td>0.670423</td>\n",
              "      <td>155</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16</td>\n",
              "      <td>0.938272</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.944099</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.091161</td>\n",
              "      <td>0.802469</td>\n",
              "      <td>0.823944</td>\n",
              "      <td>0.813065</td>\n",
              "      <td>0.980442</td>\n",
              "      <td>0.779208</td>\n",
              "      <td>0.869427</td>\n",
              "      <td>0.957895</td>\n",
              "      <td>0.911519</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.780142</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.811808</td>\n",
              "      <td>130</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.649485</td>\n",
              "      <td>0.812903</td>\n",
              "      <td>0.722063</td>\n",
              "      <td>155</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.089044</td>\n",
              "      <td>0.784960</td>\n",
              "      <td>0.838028</td>\n",
              "      <td>0.810627</td>\n",
              "      <td>0.980134</td>\n",
              "      <td>0.777881</td>\n",
              "      <td>0.869841</td>\n",
              "      <td>0.961404</td>\n",
              "      <td>0.913333</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.745098</td>\n",
              "      <td>0.876923</td>\n",
              "      <td>0.805654</td>\n",
              "      <td>130</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.623810</td>\n",
              "      <td>0.845161</td>\n",
              "      <td>0.717808</td>\n",
              "      <td>155</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [19/19 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-16 10:57:48,767] Trial 2 finished with value: 0.7778806426827581 and parameters: {'learning_rate': 1.3482448887298277e-05, 'batch_size': 32, 'num_train_epochs': 6, 'weight_decay': 0.011371726970768803}. Best is trial 1 with value: 0.8182746401597264.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='550' max='550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [550/550 02:51, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Overall Precision</th>\n",
              "      <th>Overall Recall</th>\n",
              "      <th>Overall F1</th>\n",
              "      <th>Overall Accuracy</th>\n",
              "      <th>F1 Macro Weighted</th>\n",
              "      <th>Precision Version</th>\n",
              "      <th>Recall Version</th>\n",
              "      <th>F1 Version</th>\n",
              "      <th>Number Version</th>\n",
              "      <th>Precision Alternativename</th>\n",
              "      <th>Recall Alternativename</th>\n",
              "      <th>F1 Alternativename</th>\n",
              "      <th>Number Alternativename</th>\n",
              "      <th>Precision Extension</th>\n",
              "      <th>Recall Extension</th>\n",
              "      <th>F1 Extension</th>\n",
              "      <th>Number Extension</th>\n",
              "      <th>Precision Citation</th>\n",
              "      <th>Recall Citation</th>\n",
              "      <th>F1 Citation</th>\n",
              "      <th>Number Citation</th>\n",
              "      <th>Precision License</th>\n",
              "      <th>Recall License</th>\n",
              "      <th>F1 License</th>\n",
              "      <th>Number License</th>\n",
              "      <th>Precision Developer</th>\n",
              "      <th>Recall Developer</th>\n",
              "      <th>F1 Developer</th>\n",
              "      <th>Number Developer</th>\n",
              "      <th>Precision Release</th>\n",
              "      <th>Recall Release</th>\n",
              "      <th>F1 Release</th>\n",
              "      <th>Number Release</th>\n",
              "      <th>Precision Url</th>\n",
              "      <th>Recall Url</th>\n",
              "      <th>F1 Url</th>\n",
              "      <th>Number Url</th>\n",
              "      <th>Precision Abbreviation</th>\n",
              "      <th>Recall Abbreviation</th>\n",
              "      <th>F1 Abbreviation</th>\n",
              "      <th>Number Abbreviation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.062100</td>\n",
              "      <td>0.122591</td>\n",
              "      <td>0.739803</td>\n",
              "      <td>0.740845</td>\n",
              "      <td>0.740324</td>\n",
              "      <td>0.974045</td>\n",
              "      <td>0.697291</td>\n",
              "      <td>0.861199</td>\n",
              "      <td>0.957895</td>\n",
              "      <td>0.906977</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.696629</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>0.805195</td>\n",
              "      <td>130</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.395522</td>\n",
              "      <td>0.341935</td>\n",
              "      <td>0.366782</td>\n",
              "      <td>155</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16</td>\n",
              "      <td>0.926829</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.938272</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.065500</td>\n",
              "      <td>0.060117</td>\n",
              "      <td>0.820513</td>\n",
              "      <td>0.856338</td>\n",
              "      <td>0.838043</td>\n",
              "      <td>0.984070</td>\n",
              "      <td>0.820172</td>\n",
              "      <td>0.898361</td>\n",
              "      <td>0.961404</td>\n",
              "      <td>0.928814</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.801471</td>\n",
              "      <td>0.838462</td>\n",
              "      <td>0.819549</td>\n",
              "      <td>130</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.717277</td>\n",
              "      <td>0.883871</td>\n",
              "      <td>0.791908</td>\n",
              "      <td>155</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.529412</td>\n",
              "      <td>16</td>\n",
              "      <td>0.962025</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.955975</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.041100</td>\n",
              "      <td>0.053952</td>\n",
              "      <td>0.807592</td>\n",
              "      <td>0.869014</td>\n",
              "      <td>0.837178</td>\n",
              "      <td>0.986162</td>\n",
              "      <td>0.827186</td>\n",
              "      <td>0.907285</td>\n",
              "      <td>0.961404</td>\n",
              "      <td>0.933560</td>\n",
              "      <td>285</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.808511</td>\n",
              "      <td>0.876923</td>\n",
              "      <td>0.841328</td>\n",
              "      <td>130</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>9</td>\n",
              "      <td>0.720207</td>\n",
              "      <td>0.896774</td>\n",
              "      <td>0.798851</td>\n",
              "      <td>155</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.418605</td>\n",
              "      <td>16</td>\n",
              "      <td>0.938272</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.944099</td>\n",
              "      <td>80</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [74/74 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-16 11:00:46,356] Trial 3 finished with value: 0.8271862407652768 and parameters: {'learning_rate': 1.2618058581844125e-05, 'batch_size': 8, 'num_train_epochs': 5, 'weight_decay': 4.038753090994087e-05}. Best is trial 3 with value: 0.8271862407652768.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1320' max='1320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1320/1320 04:07, Epoch 5/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Overall Precision</th>\n",
              "      <th>Overall Recall</th>\n",
              "      <th>Overall F1</th>\n",
              "      <th>Overall Accuracy</th>\n",
              "      <th>F1 Macro Weighted</th>\n",
              "      <th>Precision Version</th>\n",
              "      <th>Recall Version</th>\n",
              "      <th>F1 Version</th>\n",
              "      <th>Number Version</th>\n",
              "      <th>Precision Alternativename</th>\n",
              "      <th>Recall Alternativename</th>\n",
              "      <th>F1 Alternativename</th>\n",
              "      <th>Number Alternativename</th>\n",
              "      <th>Precision Extension</th>\n",
              "      <th>Recall Extension</th>\n",
              "      <th>F1 Extension</th>\n",
              "      <th>Number Extension</th>\n",
              "      <th>Precision Citation</th>\n",
              "      <th>Recall Citation</th>\n",
              "      <th>F1 Citation</th>\n",
              "      <th>Number Citation</th>\n",
              "      <th>Precision License</th>\n",
              "      <th>Recall License</th>\n",
              "      <th>F1 License</th>\n",
              "      <th>Number License</th>\n",
              "      <th>Precision Developer</th>\n",
              "      <th>Recall Developer</th>\n",
              "      <th>F1 Developer</th>\n",
              "      <th>Number Developer</th>\n",
              "      <th>Precision Release</th>\n",
              "      <th>Recall Release</th>\n",
              "      <th>F1 Release</th>\n",
              "      <th>Number Release</th>\n",
              "      <th>Precision Url</th>\n",
              "      <th>Recall Url</th>\n",
              "      <th>F1 Url</th>\n",
              "      <th>Number Url</th>\n",
              "      <th>Precision Abbreviation</th>\n",
              "      <th>Recall Abbreviation</th>\n",
              "      <th>F1 Abbreviation</th>\n",
              "      <th>Number Abbreviation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.173700</td>\n",
              "      <td>0.097652</td>\n",
              "      <td>0.814346</td>\n",
              "      <td>0.815493</td>\n",
              "      <td>0.814919</td>\n",
              "      <td>0.980257</td>\n",
              "      <td>0.779494</td>\n",
              "      <td>0.903010</td>\n",
              "      <td>0.947368</td>\n",
              "      <td>0.924658</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.681319</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>0.794872</td>\n",
              "      <td>130</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.736486</td>\n",
              "      <td>0.703226</td>\n",
              "      <td>0.719472</td>\n",
              "      <td>155</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16</td>\n",
              "      <td>0.926829</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.938272</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.042200</td>\n",
              "      <td>0.051235</td>\n",
              "      <td>0.827048</td>\n",
              "      <td>0.895775</td>\n",
              "      <td>0.860041</td>\n",
              "      <td>0.987453</td>\n",
              "      <td>0.859493</td>\n",
              "      <td>0.901639</td>\n",
              "      <td>0.964912</td>\n",
              "      <td>0.932203</td>\n",
              "      <td>285</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>10</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>10</td>\n",
              "      <td>0.820144</td>\n",
              "      <td>0.876923</td>\n",
              "      <td>0.847584</td>\n",
              "      <td>130</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>9</td>\n",
              "      <td>0.765957</td>\n",
              "      <td>0.929032</td>\n",
              "      <td>0.839650</td>\n",
              "      <td>155</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.418605</td>\n",
              "      <td>16</td>\n",
              "      <td>0.938272</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.944099</td>\n",
              "      <td>80</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.018700</td>\n",
              "      <td>0.049144</td>\n",
              "      <td>0.873800</td>\n",
              "      <td>0.897183</td>\n",
              "      <td>0.885337</td>\n",
              "      <td>0.989175</td>\n",
              "      <td>0.885809</td>\n",
              "      <td>0.923333</td>\n",
              "      <td>0.971930</td>\n",
              "      <td>0.947009</td>\n",
              "      <td>285</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>10</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>10</td>\n",
              "      <td>0.892562</td>\n",
              "      <td>0.830769</td>\n",
              "      <td>0.860558</td>\n",
              "      <td>130</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>9</td>\n",
              "      <td>0.827381</td>\n",
              "      <td>0.896774</td>\n",
              "      <td>0.860681</td>\n",
              "      <td>155</td>\n",
              "      <td>0.409091</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>16</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>80</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.758621</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.017600</td>\n",
              "      <td>0.048906</td>\n",
              "      <td>0.862850</td>\n",
              "      <td>0.912676</td>\n",
              "      <td>0.887064</td>\n",
              "      <td>0.989360</td>\n",
              "      <td>0.889619</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.968421</td>\n",
              "      <td>0.945205</td>\n",
              "      <td>285</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>10</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>10</td>\n",
              "      <td>0.846715</td>\n",
              "      <td>0.892308</td>\n",
              "      <td>0.868914</td>\n",
              "      <td>130</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>9</td>\n",
              "      <td>0.839286</td>\n",
              "      <td>0.909677</td>\n",
              "      <td>0.873065</td>\n",
              "      <td>155</td>\n",
              "      <td>0.360000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.439024</td>\n",
              "      <td>16</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>80</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.709677</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='148' max='148' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [148/148 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-16 11:04:59,888] Trial 4 finished with value: 0.8896188587836443 and parameters: {'learning_rate': 1.1919459316702425e-05, 'batch_size': 4, 'num_train_epochs': 6, 'weight_decay': 0.02374607192919603}. Best is trial 4 with value: 0.8896188587836443.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='140' max='140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [140/140 02:55, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Overall Precision</th>\n",
              "      <th>Overall Recall</th>\n",
              "      <th>Overall F1</th>\n",
              "      <th>Overall Accuracy</th>\n",
              "      <th>F1 Macro Weighted</th>\n",
              "      <th>Precision Version</th>\n",
              "      <th>Recall Version</th>\n",
              "      <th>F1 Version</th>\n",
              "      <th>Number Version</th>\n",
              "      <th>Precision Alternativename</th>\n",
              "      <th>Recall Alternativename</th>\n",
              "      <th>F1 Alternativename</th>\n",
              "      <th>Number Alternativename</th>\n",
              "      <th>Precision Extension</th>\n",
              "      <th>Recall Extension</th>\n",
              "      <th>F1 Extension</th>\n",
              "      <th>Number Extension</th>\n",
              "      <th>Precision Citation</th>\n",
              "      <th>Recall Citation</th>\n",
              "      <th>F1 Citation</th>\n",
              "      <th>Number Citation</th>\n",
              "      <th>Precision License</th>\n",
              "      <th>Recall License</th>\n",
              "      <th>F1 License</th>\n",
              "      <th>Number License</th>\n",
              "      <th>Precision Developer</th>\n",
              "      <th>Recall Developer</th>\n",
              "      <th>F1 Developer</th>\n",
              "      <th>Number Developer</th>\n",
              "      <th>Precision Release</th>\n",
              "      <th>Recall Release</th>\n",
              "      <th>F1 Release</th>\n",
              "      <th>Number Release</th>\n",
              "      <th>Precision Url</th>\n",
              "      <th>Recall Url</th>\n",
              "      <th>F1 Url</th>\n",
              "      <th>Number Url</th>\n",
              "      <th>Precision Abbreviation</th>\n",
              "      <th>Recall Abbreviation</th>\n",
              "      <th>F1 Abbreviation</th>\n",
              "      <th>Number Abbreviation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.337775</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.937696</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>130</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>155</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.163509</td>\n",
              "      <td>0.763293</td>\n",
              "      <td>0.626761</td>\n",
              "      <td>0.688322</td>\n",
              "      <td>0.966050</td>\n",
              "      <td>0.613550</td>\n",
              "      <td>0.894915</td>\n",
              "      <td>0.926316</td>\n",
              "      <td>0.910345</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.876923</td>\n",
              "      <td>0.786207</td>\n",
              "      <td>130</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.049180</td>\n",
              "      <td>0.019355</td>\n",
              "      <td>0.027778</td>\n",
              "      <td>155</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16</td>\n",
              "      <td>0.955224</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.870748</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.110982</td>\n",
              "      <td>0.723347</td>\n",
              "      <td>0.754930</td>\n",
              "      <td>0.738801</td>\n",
              "      <td>0.976567</td>\n",
              "      <td>0.713663</td>\n",
              "      <td>0.871383</td>\n",
              "      <td>0.950877</td>\n",
              "      <td>0.909396</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.731544</td>\n",
              "      <td>0.838462</td>\n",
              "      <td>0.781362</td>\n",
              "      <td>130</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.396040</td>\n",
              "      <td>0.516129</td>\n",
              "      <td>0.448179</td>\n",
              "      <td>155</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16</td>\n",
              "      <td>0.962025</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.955975</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.559300</td>\n",
              "      <td>0.092935</td>\n",
              "      <td>0.729084</td>\n",
              "      <td>0.773239</td>\n",
              "      <td>0.750513</td>\n",
              "      <td>0.977366</td>\n",
              "      <td>0.724876</td>\n",
              "      <td>0.872611</td>\n",
              "      <td>0.961404</td>\n",
              "      <td>0.914858</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.741722</td>\n",
              "      <td>0.861538</td>\n",
              "      <td>0.797153</td>\n",
              "      <td>130</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.418269</td>\n",
              "      <td>0.561290</td>\n",
              "      <td>0.479339</td>\n",
              "      <td>155</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.559300</td>\n",
              "      <td>0.089093</td>\n",
              "      <td>0.763329</td>\n",
              "      <td>0.826761</td>\n",
              "      <td>0.793780</td>\n",
              "      <td>0.979765</td>\n",
              "      <td>0.763066</td>\n",
              "      <td>0.859375</td>\n",
              "      <td>0.964912</td>\n",
              "      <td>0.909091</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.741722</td>\n",
              "      <td>0.861538</td>\n",
              "      <td>0.797153</td>\n",
              "      <td>130</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.568807</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.664879</td>\n",
              "      <td>155</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [19/19 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-16 11:08:02,211] Trial 5 finished with value: 0.7630663416865349 and parameters: {'learning_rate': 1.8953292783183534e-05, 'batch_size': 32, 'num_train_epochs': 5, 'weight_decay': 0.027940706621759664}. Best is trial 4 with value: 0.8896188587836443.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='550' max='550' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [550/550 02:55, Epoch 4/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Overall Precision</th>\n",
              "      <th>Overall Recall</th>\n",
              "      <th>Overall F1</th>\n",
              "      <th>Overall Accuracy</th>\n",
              "      <th>F1 Macro Weighted</th>\n",
              "      <th>Precision Version</th>\n",
              "      <th>Recall Version</th>\n",
              "      <th>F1 Version</th>\n",
              "      <th>Number Version</th>\n",
              "      <th>Precision Alternativename</th>\n",
              "      <th>Recall Alternativename</th>\n",
              "      <th>F1 Alternativename</th>\n",
              "      <th>Number Alternativename</th>\n",
              "      <th>Precision Extension</th>\n",
              "      <th>Recall Extension</th>\n",
              "      <th>F1 Extension</th>\n",
              "      <th>Number Extension</th>\n",
              "      <th>Precision Citation</th>\n",
              "      <th>Recall Citation</th>\n",
              "      <th>F1 Citation</th>\n",
              "      <th>Number Citation</th>\n",
              "      <th>Precision License</th>\n",
              "      <th>Recall License</th>\n",
              "      <th>F1 License</th>\n",
              "      <th>Number License</th>\n",
              "      <th>Precision Developer</th>\n",
              "      <th>Recall Developer</th>\n",
              "      <th>F1 Developer</th>\n",
              "      <th>Number Developer</th>\n",
              "      <th>Precision Release</th>\n",
              "      <th>Recall Release</th>\n",
              "      <th>F1 Release</th>\n",
              "      <th>Number Release</th>\n",
              "      <th>Precision Url</th>\n",
              "      <th>Recall Url</th>\n",
              "      <th>F1 Url</th>\n",
              "      <th>Number Url</th>\n",
              "      <th>Precision Abbreviation</th>\n",
              "      <th>Recall Abbreviation</th>\n",
              "      <th>F1 Abbreviation</th>\n",
              "      <th>Number Abbreviation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.983100</td>\n",
              "      <td>0.109357</td>\n",
              "      <td>0.791726</td>\n",
              "      <td>0.781690</td>\n",
              "      <td>0.786676</td>\n",
              "      <td>0.977059</td>\n",
              "      <td>0.747937</td>\n",
              "      <td>0.888525</td>\n",
              "      <td>0.950877</td>\n",
              "      <td>0.918644</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.696629</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>0.805195</td>\n",
              "      <td>130</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.617647</td>\n",
              "      <td>0.541935</td>\n",
              "      <td>0.577320</td>\n",
              "      <td>155</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16</td>\n",
              "      <td>0.926829</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.938272</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.059400</td>\n",
              "      <td>0.055807</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.856338</td>\n",
              "      <td>0.840941</td>\n",
              "      <td>0.986039</td>\n",
              "      <td>0.825925</td>\n",
              "      <td>0.910000</td>\n",
              "      <td>0.957895</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.816176</td>\n",
              "      <td>0.853846</td>\n",
              "      <td>0.834586</td>\n",
              "      <td>130</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>9</td>\n",
              "      <td>0.743169</td>\n",
              "      <td>0.877419</td>\n",
              "      <td>0.804734</td>\n",
              "      <td>155</td>\n",
              "      <td>0.450000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>16</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.034800</td>\n",
              "      <td>0.051326</td>\n",
              "      <td>0.829396</td>\n",
              "      <td>0.890141</td>\n",
              "      <td>0.858696</td>\n",
              "      <td>0.987330</td>\n",
              "      <td>0.857649</td>\n",
              "      <td>0.916388</td>\n",
              "      <td>0.961404</td>\n",
              "      <td>0.938356</td>\n",
              "      <td>285</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>10</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>10</td>\n",
              "      <td>0.809859</td>\n",
              "      <td>0.884615</td>\n",
              "      <td>0.845588</td>\n",
              "      <td>130</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>9</td>\n",
              "      <td>0.770492</td>\n",
              "      <td>0.909677</td>\n",
              "      <td>0.834320</td>\n",
              "      <td>155</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.418605</td>\n",
              "      <td>16</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>80</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.592593</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [74/74 00:02]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-16 11:11:03,201] Trial 6 finished with value: 0.8576489211815906 and parameters: {'learning_rate': 1.5117756753273184e-05, 'batch_size': 8, 'num_train_epochs': 5, 'weight_decay': 1.651580629308851e-05}. Best is trial 4 with value: 0.8896188587836443.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='330' max='330' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [330/330 03:10, Epoch 5/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Overall Precision</th>\n",
              "      <th>Overall Recall</th>\n",
              "      <th>Overall F1</th>\n",
              "      <th>Overall Accuracy</th>\n",
              "      <th>F1 Macro Weighted</th>\n",
              "      <th>Precision Version</th>\n",
              "      <th>Recall Version</th>\n",
              "      <th>F1 Version</th>\n",
              "      <th>Number Version</th>\n",
              "      <th>Precision Alternativename</th>\n",
              "      <th>Recall Alternativename</th>\n",
              "      <th>F1 Alternativename</th>\n",
              "      <th>Number Alternativename</th>\n",
              "      <th>Precision Extension</th>\n",
              "      <th>Recall Extension</th>\n",
              "      <th>F1 Extension</th>\n",
              "      <th>Number Extension</th>\n",
              "      <th>Precision Citation</th>\n",
              "      <th>Recall Citation</th>\n",
              "      <th>F1 Citation</th>\n",
              "      <th>Number Citation</th>\n",
              "      <th>Precision License</th>\n",
              "      <th>Recall License</th>\n",
              "      <th>F1 License</th>\n",
              "      <th>Number License</th>\n",
              "      <th>Precision Developer</th>\n",
              "      <th>Recall Developer</th>\n",
              "      <th>F1 Developer</th>\n",
              "      <th>Number Developer</th>\n",
              "      <th>Precision Release</th>\n",
              "      <th>Recall Release</th>\n",
              "      <th>F1 Release</th>\n",
              "      <th>Number Release</th>\n",
              "      <th>Precision Url</th>\n",
              "      <th>Recall Url</th>\n",
              "      <th>F1 Url</th>\n",
              "      <th>Number Url</th>\n",
              "      <th>Precision Abbreviation</th>\n",
              "      <th>Recall Abbreviation</th>\n",
              "      <th>F1 Abbreviation</th>\n",
              "      <th>Number Abbreviation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.133467</td>\n",
              "      <td>0.747692</td>\n",
              "      <td>0.684507</td>\n",
              "      <td>0.714706</td>\n",
              "      <td>0.970847</td>\n",
              "      <td>0.660264</td>\n",
              "      <td>0.903780</td>\n",
              "      <td>0.922807</td>\n",
              "      <td>0.913194</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.696629</td>\n",
              "      <td>0.953846</td>\n",
              "      <td>0.805195</td>\n",
              "      <td>130</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.227723</td>\n",
              "      <td>0.148387</td>\n",
              "      <td>0.179687</td>\n",
              "      <td>155</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.581600</td>\n",
              "      <td>0.053116</td>\n",
              "      <td>0.840108</td>\n",
              "      <td>0.873239</td>\n",
              "      <td>0.856354</td>\n",
              "      <td>0.985792</td>\n",
              "      <td>0.853232</td>\n",
              "      <td>0.915825</td>\n",
              "      <td>0.954386</td>\n",
              "      <td>0.934708</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.461538</td>\n",
              "      <td>10</td>\n",
              "      <td>0.835938</td>\n",
              "      <td>0.823077</td>\n",
              "      <td>0.829457</td>\n",
              "      <td>130</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>9</td>\n",
              "      <td>0.787709</td>\n",
              "      <td>0.909677</td>\n",
              "      <td>0.844311</td>\n",
              "      <td>155</td>\n",
              "      <td>0.409091</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.473684</td>\n",
              "      <td>16</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>80</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.551724</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.042600</td>\n",
              "      <td>0.050768</td>\n",
              "      <td>0.852785</td>\n",
              "      <td>0.905634</td>\n",
              "      <td>0.878415</td>\n",
              "      <td>0.988191</td>\n",
              "      <td>0.878902</td>\n",
              "      <td>0.925926</td>\n",
              "      <td>0.964912</td>\n",
              "      <td>0.945017</td>\n",
              "      <td>285</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>10</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>10</td>\n",
              "      <td>0.824818</td>\n",
              "      <td>0.869231</td>\n",
              "      <td>0.846442</td>\n",
              "      <td>130</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>9</td>\n",
              "      <td>0.786517</td>\n",
              "      <td>0.903226</td>\n",
              "      <td>0.840841</td>\n",
              "      <td>155</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.685714</td>\n",
              "      <td>16</td>\n",
              "      <td>0.938272</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.944099</td>\n",
              "      <td>80</td>\n",
              "      <td>0.578947</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.021200</td>\n",
              "      <td>0.050987</td>\n",
              "      <td>0.853403</td>\n",
              "      <td>0.918310</td>\n",
              "      <td>0.884668</td>\n",
              "      <td>0.988437</td>\n",
              "      <td>0.886399</td>\n",
              "      <td>0.923077</td>\n",
              "      <td>0.968421</td>\n",
              "      <td>0.945205</td>\n",
              "      <td>285</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.705882</td>\n",
              "      <td>10</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>10</td>\n",
              "      <td>0.825175</td>\n",
              "      <td>0.907692</td>\n",
              "      <td>0.864469</td>\n",
              "      <td>130</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>9</td>\n",
              "      <td>0.804598</td>\n",
              "      <td>0.903226</td>\n",
              "      <td>0.851064</td>\n",
              "      <td>155</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.631579</td>\n",
              "      <td>16</td>\n",
              "      <td>0.938272</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.944099</td>\n",
              "      <td>80</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [37/37 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-16 11:14:21,029] Trial 7 finished with value: 0.8863994096656127 and parameters: {'learning_rate': 3.340689577220468e-05, 'batch_size': 16, 'num_train_epochs': 6, 'weight_decay': 0.050388269317350444}. Best is trial 4 with value: 0.8896188587836443.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='165' max='165' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [165/165 01:34, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Overall Precision</th>\n",
              "      <th>Overall Recall</th>\n",
              "      <th>Overall F1</th>\n",
              "      <th>Overall Accuracy</th>\n",
              "      <th>F1 Macro Weighted</th>\n",
              "      <th>Precision Version</th>\n",
              "      <th>Recall Version</th>\n",
              "      <th>F1 Version</th>\n",
              "      <th>Number Version</th>\n",
              "      <th>Precision Alternativename</th>\n",
              "      <th>Recall Alternativename</th>\n",
              "      <th>F1 Alternativename</th>\n",
              "      <th>Number Alternativename</th>\n",
              "      <th>Precision Extension</th>\n",
              "      <th>Recall Extension</th>\n",
              "      <th>F1 Extension</th>\n",
              "      <th>Number Extension</th>\n",
              "      <th>Precision Citation</th>\n",
              "      <th>Recall Citation</th>\n",
              "      <th>F1 Citation</th>\n",
              "      <th>Number Citation</th>\n",
              "      <th>Precision License</th>\n",
              "      <th>Recall License</th>\n",
              "      <th>F1 License</th>\n",
              "      <th>Number License</th>\n",
              "      <th>Precision Developer</th>\n",
              "      <th>Recall Developer</th>\n",
              "      <th>F1 Developer</th>\n",
              "      <th>Number Developer</th>\n",
              "      <th>Precision Release</th>\n",
              "      <th>Recall Release</th>\n",
              "      <th>F1 Release</th>\n",
              "      <th>Number Release</th>\n",
              "      <th>Precision Url</th>\n",
              "      <th>Recall Url</th>\n",
              "      <th>F1 Url</th>\n",
              "      <th>Number Url</th>\n",
              "      <th>Precision Abbreviation</th>\n",
              "      <th>Recall Abbreviation</th>\n",
              "      <th>F1 Abbreviation</th>\n",
              "      <th>Number Abbreviation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.216122</td>\n",
              "      <td>0.945736</td>\n",
              "      <td>0.343662</td>\n",
              "      <td>0.504132</td>\n",
              "      <td>0.952642</td>\n",
              "      <td>0.403081</td>\n",
              "      <td>0.947137</td>\n",
              "      <td>0.754386</td>\n",
              "      <td>0.839844</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.935484</td>\n",
              "      <td>0.223077</td>\n",
              "      <td>0.360248</td>\n",
              "      <td>130</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>155</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.671000</td>\n",
              "      <td>0.093758</td>\n",
              "      <td>0.775839</td>\n",
              "      <td>0.814085</td>\n",
              "      <td>0.794502</td>\n",
              "      <td>0.979458</td>\n",
              "      <td>0.762225</td>\n",
              "      <td>0.869427</td>\n",
              "      <td>0.957895</td>\n",
              "      <td>0.911519</td>\n",
              "      <td>285</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.861538</td>\n",
              "      <td>0.788732</td>\n",
              "      <td>130</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9</td>\n",
              "      <td>0.596939</td>\n",
              "      <td>0.754839</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>155</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16</td>\n",
              "      <td>0.938272</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>0.944099</td>\n",
              "      <td>80</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [37/37 00:03]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-07-16 11:16:02,908] Trial 8 finished with value: 0.762224600747695 and parameters: {'learning_rate': 1.4293914088113572e-05, 'batch_size': 16, 'num_train_epochs': 3, 'weight_decay': 0.0006987185712216486}. Best is trial 4 with value: 0.8896188587836443.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='22' max='112' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 22/112 00:23 < 01:44, 0.87 it/s, Epoch 0.75/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import optuna\n",
        "from transformers import Trainer, TrainingArguments, BertForTokenClassification\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "def model_init():\n",
        "    return BertForTokenClassification.from_pretrained(model_name, num_labels=len(unique_labels), return_dict=True)\n",
        "\n",
        "\n",
        "\n",
        "def objective(trial):\n",
        "    learning_rate = trial.suggest_float('learning_rate',  1e-5, 5e-5, log=True)\n",
        "    batch_size = trial.suggest_categorical('batch_size', [4, 8, 16, 32])\n",
        "    epochs = trial.suggest_int(\"num_train_epochs\", 3, 7)\n",
        "    weight_decay = trial.suggest_float(\"weight_decay\",  1e-5, 0.1, log=True)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"./output\",\n",
        "        eval_strategy=\"epoch\",\n",
        "        learning_rate=learning_rate,\n",
        "        per_device_train_batch_size=batch_size,\n",
        "        per_device_eval_batch_size=batch_size,\n",
        "        num_train_epochs=epochs,\n",
        "        weight_decay=weight_decay,\n",
        "        logging_dir='./logs',\n",
        "        logging_steps=100,\n",
        "        warmup_ratio=0.1,\n",
        "        gradient_accumulation_steps=2,\n",
        "        max_grad_norm=1.0\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model_init=model_init,\n",
        "        args=training_args,\n",
        "        train_dataset=Train_dataset,\n",
        "        eval_dataset=Val_dataset,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    eval_result = trainer.evaluate()\n",
        "    overall_f1 = eval_result['eval_f1_macro_weighted']\n",
        "    return overall_f1\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "assert len(study.trials) == 0\n",
        "study.optimize(objective, n_trials=20)\n",
        "\n",
        "if len(study.trials) == 0 or all([t.state != optuna.trial.TrialState.COMPLETE for t in study.trials]):\n",
        "    print(\"No trials are completed yet.\")\n",
        "else:\n",
        "  print(\"Best trial:\")\n",
        "  trial = study.best_trial\n",
        "  print(trial.values)\n",
        "  print(\"Best hyperparameters: {}\".format(trial.params))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9ea46c4",
      "metadata": {
        "id": "f9ea46c4"
      },
      "source": [
        "## Retrain with best parameters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "V"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "7KzdSXszDNrf",
        "outputId": "f3e8e40f-58a4-4b8f-ffaa-e53cec4e63f4"
      },
      "id": "7KzdSXszDNrf",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'V' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-af688aeda998>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'V' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43659428",
      "metadata": {
        "id": "43659428"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "trial.params, trial.value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5un7fVFcDjs-",
        "outputId": "17ffd0c9-fd72-4c82-f319-b107c504bfdf"
      },
      "id": "5un7fVFcDjs-",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'learning_rate': 4.03137219824488e-05,\n",
              "  'batch_size': 4,\n",
              "  'num_train_epochs': 5,\n",
              "  'weight_decay': 2.6675525585646302e-05},\n",
              " 0.8789546079779919)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TjBTu04dDlRg"
      },
      "id": "TjBTu04dDlRg",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}