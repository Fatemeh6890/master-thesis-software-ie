{'num_train_epochs': 10, 'learning_rate': 0.00015515173680859392, 'per_device_train_batch_size': 4, 'per_device_eval_batch_size': 16, 'weight_decay': 0.005460881581285625, 'eval_strategy': 'epoch', 'logging_dir': './logs', 'logging_steps': 100, 'warmup_ratio': 0.1, 'gradient_accumulation_steps': 2, 'max_grad_norm': 1.0, 'disable_tqdm': False, 'model_name': 'roberta-base'}
