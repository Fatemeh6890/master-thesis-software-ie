{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf7c50a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install evaluate\n",
    "# !pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "758df96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install accelerate -U\n",
    "# !pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39f53ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')\n",
    "import helper\n",
    "import collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b90a759",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe05fad7",
   "metadata": {},
   "source": [
    "### Read the Train Dataset (Sentences and Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37d746ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the Data of Sentences\n",
    "with open('../../data/subtask1/subtask1_train.data.txt', 'r', encoding='utf-8') as file:\n",
    "    sentences = file.readlines()\n",
    "\n",
    "\n",
    "# Open the label data\n",
    "with open('../../data/subtask1/subtask1_train.labels.txt', 'r', encoding='utf-8') as file:\n",
    "    labels = file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b31503f",
   "metadata": {},
   "source": [
    "### Convert the Dataset into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f73c1764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.DataFrame(list(zip(sentences, labels)), columns=['sentences', 'labels'])\n",
    "# split sentences and labels\n",
    "dataset['sentences'] = dataset['sentences'].apply(lambda row: row.split())\n",
    "dataset['labels'] = dataset['labels'].apply(lambda row: row.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705dee45",
   "metadata": {},
   "source": [
    "### Unique labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55e40869",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = []\n",
    "\n",
    "for line in labels:\n",
    "    labels_list = line.split()\n",
    "    for label in labels_list:\n",
    "        if label not in unique_labels:\n",
    "            unique_labels.append(label)\n",
    "            \n",
    "uniqueLabel_to_ID = {unique_label: ID for ID, unique_label in enumerate(unique_labels)}\n",
    "ID_to_uniqueLable = {ID: unique_label for ID, unique_label in enumerate(unique_labels)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b51fd7",
   "metadata": {},
   "source": [
    "### Map each label to its ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf0175c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['IDs'] = dataset['labels'].apply(lambda row: [uniqueLabel_to_ID.get(label) for label in row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c0fef1",
   "metadata": {},
   "source": [
    "# Prepare the train and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57ac078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, validation = train_test_split(dataset, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd115e3",
   "metadata": {},
   "source": [
    "## Tokenize and convet the labels from tokenized into IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11bc4b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, AutoTokenizer\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85748a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(input_data):\n",
    "    tokenized_train_inputs = tokenizer(\n",
    "        input_data,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        is_split_into_words=True,\n",
    "        padding=\"do_not_pad\",\n",
    "        max_length=512,\n",
    "    )\n",
    "    \n",
    "    return tokenized_train_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222e0cf3",
   "metadata": {},
   "source": [
    "### Trian Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7c5e9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tokenized'] = train.apply(lambda row: helper.tokenized_align_labels(tokenization(row['sentences']), row['IDs']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0655d10b",
   "metadata": {},
   "source": [
    "### Validation Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbe5ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation['tokenized'] = validation.apply(lambda row: helper.tokenized_align_labels(tokenization(row['sentences']), row['IDs']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0fb924",
   "metadata": {},
   "source": [
    "### Prepare Train dataset for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fc94238",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_dataset = train.tokenized.apply(\n",
    "    lambda x: {\n",
    "        k: v[0]\n",
    "        if type(v) is not list\n",
    "        else torch.tensor(v)\n",
    "        for k, v in x.items()}).to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc46abe",
   "metadata": {},
   "source": [
    "### Prepare validation dataset for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c3db94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Val_dataset = validation.tokenized.apply(\n",
    "    lambda x: {\n",
    "        k: v[0]\n",
    "        if type(v) is not list\n",
    "        else torch.tensor(v)\n",
    "        for k, v in x.items()}).to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b2bea5",
   "metadata": {},
   "source": [
    "## Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "113e9bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "### todo guck mal nach cased und uncased ob es mit cased besser funktioniert oder mit uncased\n",
    "model_name = \"bert-base-uncased\"\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name, id2label=ID_to_uniqueLable, num_labels=len(unique_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e63bba7",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c5e4fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "metric = evaluate.load('seqeval')\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds, label_class=unique_labels):\n",
    "    logits, labels = eval_preds\n",
    "    # becase the logics and probabilities both are in the same order, we don't need to aply softmax here\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    # now we need to remove all the values, where the label is -100\n",
    "    # before passing to metric.compute we should have these inputs as a list\n",
    "    true_labels = [[label_class[l] for l in label if l != -100]\n",
    "                   for label in labels]\n",
    "\n",
    "    true_predictions = [[label_class[p] for p,l in zip(prediction, label) if l != -100]\n",
    "                        for prediction, label in zip(predictions, labels)]\n",
    "\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    return all_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d0c795",
   "metadata": {},
   "source": [
    "# Parameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea537d0b",
   "metadata": {},
   "source": [
    "## Define the hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77187321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers optuna datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d12b68a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-13 18:59:49,862] A new study created in memory with name: no-name-eaec023f-d28e-4064-ae4b-0210fd895a6b\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_6248\\3668417859.py:26: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_6248\\3668417859.py:28: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  epochs = trial.suggest_int(\"num_train_epochs\", 7, 8, 9)\n",
      "C:\\Users\\fschr\\AppData\\Roaming\\Python\\Python311\\site-packages\\optuna\\distributions.py:700: UserWarning: The distribution is specified by [7, 8] and step=9, but the range is not divisible by `step`. It will be replaced by [7, 7].\n",
      "  warnings.warn(\n",
      "C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_6248\\3668417859.py:29: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  weight_decay = trial.suggest_loguniform(\"weight_decay\", 0.1, 0.3)\n",
      "C:\\Users\\fschr\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "[W 2024-07-13 18:59:57,217] Trial 0 failed with parameters: {'learning_rate': 1.8351014706990397e-05, 'batch_size': 16, 'num_train_epochs': 7, 'weight_decay': 0.28156206639227876} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\fschr\\AppData\\Roaming\\Python\\Python311\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_6248\\3668417859.py\", line 54, in objective\n",
      "    trainer.train()\n",
      "  File \"C:\\Users\\fschr\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\trainer.py\", line 1932, in train\n",
      "    return inner_training_loop(\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fschr\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\trainer.py\", line 2268, in _inner_training_loop\n",
      "    tr_loss_step = self.training_step(model, inputs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\fschr\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\trainer.py\", line 3324, in training_step\n",
      "    self.accelerator.backward(loss, **kwargs)\n",
      "  File \"C:\\Users\\fschr\\AppData\\Roaming\\Python\\Python311\\site-packages\\accelerate\\accelerator.py\", line 2151, in backward\n",
      "    loss.backward(**kwargs)\n",
      "  File \"C:\\Users\\fschr\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_tensor.py\", line 492, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"C:\\Users\\fschr\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\__init__.py\", line 251, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "[W 2024-07-13 18:59:57,233] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 60\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m eval_result\n\u001b[0;32m     59\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 60\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     63\u001b[0m trial \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_trial\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     _optimize(\n\u001b[0;32m    452\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    453\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m    454\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[0;32m    455\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    456\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    457\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[0;32m    458\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    459\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[0;32m    460\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[0;32m    461\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         _optimize_sequential(\n\u001b[0;32m     63\u001b[0m             study,\n\u001b[0;32m     64\u001b[0m             func,\n\u001b[0;32m     65\u001b[0m             n_trials,\n\u001b[0;32m     66\u001b[0m             timeout,\n\u001b[0;32m     67\u001b[0m             catch,\n\u001b[0;32m     68\u001b[0m             callbacks,\n\u001b[0;32m     69\u001b[0m             gc_after_trial,\n\u001b[0;32m     70\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     71\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     72\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[0;32m     73\u001b[0m         )\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[20], line 54\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     31\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[0;32m     32\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     33\u001b[0m     evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m     logging_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     41\u001b[0m )\n\u001b[0;32m     45\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     46\u001b[0m     model_init\u001b[38;5;241m=\u001b[39mmodel_init,\n\u001b[0;32m     47\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     51\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[0;32m     52\u001b[0m )\n\u001b[1;32m---> 54\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     56\u001b[0m eval_result \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m eval_result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\trainer.py:1932\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1930\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1933\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   1934\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[0;32m   1935\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[0;32m   1936\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[0;32m   1937\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\trainer.py:2268\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   2267\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 2268\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   2270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2271\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2272\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2273\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2274\u001b[0m ):\n\u001b[0;32m   2275\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2276\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\trainer.py:3324\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3322\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m   3323\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3324\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mbackward(loss, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3326\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\accelerate\\accelerator.py:2151\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[0;32m   2150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2151\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[0;32m    493\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[0;32m    494\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    252\u001b[0m     tensors,\n\u001b[0;32m    253\u001b[0m     grad_tensors_,\n\u001b[0;32m    254\u001b[0m     retain_graph,\n\u001b[0;32m    255\u001b[0m     create_graph,\n\u001b[0;32m    256\u001b[0m     inputs,\n\u001b[0;32m    257\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    258\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    259\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from transformers import Trainer, TrainingArguments, BertForTokenClassification\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "def model_init():\n",
    "    return BertForTokenClassification.from_pretrained(model_name, num_labels=len(unique_labels))\n",
    "\n",
    "def compute_metrics(eval_preds, label_class=unique_labels):\n",
    "    logits, labels = eval_preds\n",
    "    # becase the logics and probabilities both are in the same order, we don't need to aply softmax here\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    # now we need to remove all the values, where the label is -100\n",
    "    # before passing to metric.compute we should have these inputs as a list\n",
    "    true_labels = [[label_class[l] for l in label if l != -100]\n",
    "                   for label in labels]\n",
    "\n",
    "    true_predictions = [[label_class[p] for p,l in zip(prediction, label) if l != -100]\n",
    "                        for prediction, label in zip(predictions, labels)]\n",
    "\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    return all_metrics\n",
    "\n",
    "def objective(trial):\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 5e-5)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])\n",
    "    epochs = trial.suggest_int(\"num_train_epochs\", 7, 8, 9)\n",
    "    weight_decay = trial.suggest_loguniform(\"weight_decay\", 0.1, 0.3)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=learning_rate,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        per_device_eval_batch_size=batch_size,\n",
    "        num_train_epochs=epochs,\n",
    "        weight_decay=weight_decay,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model_init=model_init,\n",
    "        args=training_args,\n",
    "        train_dataset=Train_dataset,\n",
    "        eval_dataset=Val_dataset,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    trainer.train()\n",
    "    \n",
    "    eval_result = trainer.evaluate()\n",
    "    return eval_result\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(trial.values)\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374b4e25",
   "metadata": {},
   "source": [
    "## Retrain with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e10285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62e4c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
