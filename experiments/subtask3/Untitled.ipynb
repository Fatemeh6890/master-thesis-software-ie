{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ad7e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fschr\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b91ca10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{\"precision\": 0.5473881370746695, \"recall\": 0.6599099099099099, \"f1-score\": 0.5920593854677851, \"name\": \"bert_base_uncased\", \"epochs\": 8, \"train_batch_size\": 4, \"val_batch_size\": 8, \"lr\": 3.4761989793610213e-05, \"weight_decay\": 0.00021383997220875088, \"warmup_ratio\": 0.1}\\n', '{\"precision\": 0.7863900972724502, \"recall\": 0.7864864864864864, \"f1-score\": 0.7841076303341934, \"name\": \"bert-base-uncased\", \"epochs\": 14, \"train_batch_size\": 16, \"val_batch_size\": 8, \"lr\": 3.106652647102282e-05, \"weight_decay\": 0.015974806494799283, \"warmup_ratio\": 0.010271506016946775}\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../evaluation/subtask3/subtask3_model_comparison_results.txt\") as f:\n",
    "    prediction_infos = f.readlines()\n",
    "print(prediction_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a54c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_of_predictions = []\n",
    "for pred in prediction_infos:\n",
    "    result_of_predictions.append(ast.literal_eval(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36294700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>name</th>\n",
       "      <th>epochs</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>val_batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>warmup_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.547388</td>\n",
       "      <td>0.659910</td>\n",
       "      <td>0.592059</td>\n",
       "      <td>bert_base_uncased</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.786390</td>\n",
       "      <td>0.786486</td>\n",
       "      <td>0.784108</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.015975</td>\n",
       "      <td>0.010272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall  f1-score               name  epochs  train_batch_size  \\\n",
       "0   0.547388  0.659910  0.592059  bert_base_uncased       8                 4   \n",
       "1   0.786390  0.786486  0.784108  bert-base-uncased      14                16   \n",
       "\n",
       "   val_batch_size        lr  weight_decay  warmup_ratio  \n",
       "0               8  0.000035      0.000214      0.100000  \n",
       "1               8  0.000031      0.015975      0.010272  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result_of_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c75c113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "for d in result_of_predictions:\n",
    "    metrics.append({\n",
    "#         'negative_sampling_ration': d['negative_sampling_ratio'],\n",
    "#         'name': d['name'],\n",
    "        'precision': d['precision'],\n",
    "        'recall': d['recall'],\n",
    "        'f1': d['f1-score']\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11fbdcc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{lrrr}\\n\\\\toprule\\n & precision & recall & f1 \\\\\\\\\\n\\\\midrule\\n0 & 0.547388 & 0.659910 & 0.592059 \\\\\\\\\\n1 & 0.786390 & 0.786486 & 0.784108 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics).to_latex()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26124281",
   "metadata": {},
   "source": [
    "# Models comparission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14adea2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../evaluation/subtask3/subtask3_all_model_comparison_results.txt\") as f:\n",
    "    all_prediction_infos = f.readlines()\n",
    "\n",
    "result_of_all_predictions = []\n",
    "for pred in all_prediction_infos:\n",
    "    result_of_all_predictions.append(ast.literal_eval(pred))\n",
    "\n",
    "metrics_all = []\n",
    "for d in result_of_all_predictions:\n",
    "    metrics_all.append({\n",
    "#         'negative_sampling_ration': d['negative_sampling_ratio'],\n",
    "        'name': d['name'],\n",
    "        'precision': d['precision'],\n",
    "        'recall': d['recall'],\n",
    "        'f1': d['f1-score']\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abbdd2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>name</th>\n",
       "      <th>epochs</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>val_batch_size</th>\n",
       "      <th>lr</th>\n",
       "      <th>weight_decay</th>\n",
       "      <th>warmup_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.786390</td>\n",
       "      <td>0.786486</td>\n",
       "      <td>0.784108</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.015975</td>\n",
       "      <td>0.010272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.730505</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.747167</td>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.029999</td>\n",
       "      <td>0.069334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.678521</td>\n",
       "      <td>0.776942</td>\n",
       "      <td>0.723292</td>\n",
       "      <td>scibert_uncased</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.020631</td>\n",
       "      <td>0.018750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall  f1-score               name  epochs  train_batch_size  \\\n",
       "0   0.786390  0.786486  0.784108  bert-base-uncased      14                16   \n",
       "1   0.730505  0.771429  0.747167    bert-base-cased      11                 8   \n",
       "2   0.678521  0.776942  0.723292    scibert_uncased       9                32   \n",
       "\n",
       "   val_batch_size        lr  weight_decay  warmup_ratio  \n",
       "0               8  0.000031      0.015975      0.010272  \n",
       "1               8  0.000033      0.029999      0.069334  \n",
       "2               8  0.000037      0.020631      0.018750  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result_of_all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "887c44a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{llrrr}\\n\\\\toprule\\n & name & precision & recall & f1 \\\\\\\\\\n\\\\midrule\\n0 & bert-base-uncased & 0.786390 & 0.786486 & 0.784108 \\\\\\\\\\n1 & bert-base-cased & 0.730505 & 0.771429 & 0.747167 \\\\\\\\\\n2 & scibert_uncased & 0.678521 & 0.776942 & 0.723292 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics_all).to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43aaa60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'bert-base-uncased',\n",
       "  'precision': 0.7863900972724502,\n",
       "  'recall': 0.7864864864864864,\n",
       "  'f1': 0.7841076303341934},\n",
       " {'name': 'bert-base-cased',\n",
       "  'precision': 0.7305053835095189,\n",
       "  'recall': 0.7714285714285715,\n",
       "  'f1': 0.7471671261461602},\n",
       " {'name': 'scibert_uncased',\n",
       "  'precision': 0.678520934680511,\n",
       "  'recall': 0.7769423558897243,\n",
       "  'f1': 0.7232923482758699}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6434c5e2",
   "metadata": {},
   "source": [
    "## Comparission models force one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbc51386",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../evaluation/subtask3/subtask3_all_model_comparison_results_force_one.txt\") as f:\n",
    "    all_prediction_infos_force_one = f.readlines()\n",
    "\n",
    "result_of_all_predictions_force_one = []\n",
    "for pred in all_prediction_infos_force_one:\n",
    "    result_of_all_predictions_force_one.append(ast.literal_eval(pred))\n",
    "\n",
    "metrics_all_force_one = []\n",
    "for d in result_of_all_predictions_force_one:\n",
    "    metrics_all_force_one.append({\n",
    "#         'negative_sampling_ration': d['negative_sampling_ratio'],\n",
    "        'name': d['name'],\n",
    "        'precision': d['precision'],\n",
    "        'recall': d['recall'],\n",
    "        'f1': d['f1-score']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b0b909e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.808172</td>\n",
       "      <td>0.810959</td>\n",
       "      <td>0.809044</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.838060</td>\n",
       "      <td>0.841226</td>\n",
       "      <td>0.839099</td>\n",
       "      <td>bert-base-cased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.825985</td>\n",
       "      <td>0.837017</td>\n",
       "      <td>0.830884</td>\n",
       "      <td>scibert-uncased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.856970</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>0.862243</td>\n",
       "      <td>rule based</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision    recall  f1-score               name\n",
       "0   0.808172  0.810959  0.809044  bert-base-uncased\n",
       "1   0.838060  0.841226  0.839099    bert-base-cased\n",
       "2   0.825985  0.837017  0.830884    scibert-uncased\n",
       "3   0.856970  0.872727  0.862243         rule based"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result_of_all_predictions_force_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d62fec61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{llrrr}\\n\\\\toprule\\n & name & precision & recall & f1 \\\\\\\\\\n\\\\midrule\\n0 & bert-base-uncased & 0.808172 & 0.810959 & 0.809044 \\\\\\\\\\n1 & bert-base-cased & 0.838060 & 0.841226 & 0.839099 \\\\\\\\\\n2 & scibert-uncased & 0.825985 & 0.837017 & 0.830884 \\\\\\\\\\n3 & rule based & 0.856970 & 0.872727 & 0.862243 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics_all_force_one).to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0af366",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
