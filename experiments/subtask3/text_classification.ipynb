{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdfac02e-ba25-4412-9b3f-4418cd34799d",
   "metadata": {
    "id": "827a7a6e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90462010-a1f6-4556-babc-95f78a536535",
   "metadata": {
    "id": "827a7a6e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fschr\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch import cuda\n",
    "import sys\n",
    "\n",
    "\n",
    "from transformers import DistilBertTokenizer, DataCollatorWithPadding, TextClassificationPipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7e3aaa5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "f7e3aaa5",
    "outputId": "3f83f15b-4def-48fd-c979-79a47dc823ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a56e104",
   "metadata": {
    "id": "0a56e104"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b1aa82",
   "metadata": {
    "id": "73b1aa82"
   },
   "source": [
    "### Read the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61b00b4d",
   "metadata": {
    "id": "61b00b4d"
   },
   "outputs": [],
   "source": [
    "# open the data of sentences\n",
    "with open('../../data/subtask3/subtask3_train.data.txt', 'r', encoding='utf-8') as file: \n",
    "    sentences = file.readlines()\n",
    "\n",
    "# open the entity labels\n",
    "with open('../../data/subtask3/subtask3_train.info.txt', 'r', encoding='utf-8') as file:\n",
    "    entity_labels = file.readlines()\n",
    "\n",
    "# open the data of relations\n",
    "with open('../../data/subtask3/subtask3_train.labels.txt', 'r', encoding='utf-8') as file:\n",
    "    relations_info = file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb382e8",
   "metadata": {
    "id": "8bb382e8"
   },
   "source": [
    "### Unique entity labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36268e50",
   "metadata": {
    "id": "36268e50"
   },
   "outputs": [],
   "source": [
    "# Use a set comprehension to collect unique labels\n",
    "unique_entity_labels = list({label for line in entity_labels for label in line.split()})\n",
    "# unique_entity_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607c610e",
   "metadata": {
    "id": "607c610e"
   },
   "source": [
    "### Unique relation labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90931c33-b9a1-4396-99e8-aa338debed34",
   "metadata": {
    "id": "8adc4c12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['URL_of',\n",
       " 'Extension_of',\n",
       " 'License_of',\n",
       " 'Developer_of',\n",
       " 'Version_of',\n",
       " 'Specification_of',\n",
       " 'Citation_of',\n",
       " 'PlugIn_of',\n",
       " 'Release_of',\n",
       " 'Abbreviation_of',\n",
       " 'AlternativeName_of']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_relation_labels = set()\n",
    "\n",
    "for line in relations_info:\n",
    "    relations_info_list = line.replace(';;', ' ').split()\n",
    "    unique_relation_labels.update(relation for relation in relations_info_list if not relation.isdigit())\n",
    "\n",
    "unique_relation_labels = list(unique_relation_labels)\n",
    "\n",
    "unique_relation_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d00b7f",
   "metadata": {
    "id": "32d00b7f"
   },
   "source": [
    "### Relation_label to ID and Updside down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aed62e4d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aed62e4d",
    "outputId": "ca522647-fcdc-4581-8253-62aecf70cf29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nil': 0,\n",
       " 'Developer_of': 1,\n",
       " 'Abbreviation_of': 2,\n",
       " 'URL_of': 3,\n",
       " 'Citation_of': 4,\n",
       " 'Release_of': 5,\n",
       " 'Version_of': 6,\n",
       " 'Specification_of': 7,\n",
       " 'Extension_of': 8,\n",
       " 'PlugIn_of': 9,\n",
       " 'AlternativeName_of': 10,\n",
       " 'License_of': 11}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relation_labels = ['nil', 'Developer_of', 'Abbreviation_of', 'URL_of', 'Citation_of', 'Release_of', 'Version_of',\n",
    "                   'Specification_of', 'Extension_of', 'PlugIn_of', 'AlternativeName_of', 'License_of',\n",
    "#                    'Developer_of-1', 'Abbreviation_of-1', 'URL_of-1', 'Citation_of-1', 'Release_of-1', 'Version_of-1',\n",
    "#                    'Specification_of-1', 'Extension_of-1', 'PlugIn_of-1', 'AlternativeName_of-1', 'License_of-1'\n",
    "                  ]\n",
    "\n",
    "relation_label_to_ID = {relation_label: ID for ID, relation_label in enumerate(relation_labels)}\n",
    "ID_to_relation_label = {ID: relation_label for ID, relation_label in enumerate(relation_labels)}\n",
    "relation_label_to_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c03d61a-0159-40d2-9d24-7536e2f22863",
   "metadata": {
    "id": "0867332f-29a4-4c5b-a4a2-3b0e89f0947c",
    "scrolled": true
   },
   "source": [
    "# Combine all info for each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b907f3a8-5b27-4f5d-93ff-5f60bf70ff4a",
   "metadata": {
    "id": "0867332f-29a4-4c5b-a4a2-3b0e89f0947c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "sentence_entities_relations = []\n",
    "for idx, (sentence, entity_label_list, relation_info) in enumerate(tuple(zip(sentences, entity_labels, relations_info))):\n",
    "    token = sentence.split()\n",
    "    entity_bio_tags = entity_label_list.split()\n",
    "    ents = helper.get_entities(token, entity_bio_tags)\n",
    "    ent_dict = {e['begin']:e for e in ents}\n",
    "    relations = helper.get_relations(relation_info)\n",
    "    sentence_info = dict(\n",
    "        sentence=sentence.strip(),\n",
    "        entities=ent_dict,\n",
    "        relations=relations\n",
    "    )\n",
    "    sentence_entities_relations.append(sentence_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aade99e",
   "metadata": {
    "id": "0aade99e"
   },
   "source": [
    "### Allowed subject, object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da0d1679-bdb7-400a-9717-99f02d73ef2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9dd222e-03e6-42b6-96ba-a4d83835d5df",
    "outputId": "a9f75deb-b075-4a98-f67d-95910385a1a0",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "from collections import Counter\n",
    "\n",
    "allowed_subj_obj_all = list(chain(*[helper.sentence_allowed_subj_obj(sent, allow_inverse=False) for sent in sentence_entities_relations]))\n",
    "allowed_subj_obj_counts = Counter(allowed_subj_obj_all)\n",
    "allowed_subj_obj = set(allowed_subj_obj_counts.keys())\n",
    "len(allowed_subj_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc930bd2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ba4ee291-181f-43f5-9e2e-ceb4ff8f3756",
    "outputId": "ba28f527-499e-4273-f79d-3b6e2ffa41d9",
    "scrolled": true
   },
   "source": [
    "# Create instances for each candidate relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64b86059",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ba4ee291-181f-43f5-9e2e-ceb4ff8f3756",
    "outputId": "ba28f527-499e-4273-f79d-3b6e2ffa41d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1091, 5896)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from itertools import combinations\n",
    "\n",
    "## Idea: transform sentence based\n",
    "def sent_to_relation_representations(sent, allowed_subj_obj=None):\n",
    "    rel_dict = {(r['subject'], r['object']):r['relation_type'] for r in sent['relations']}\n",
    "#     rel_dict |= {(r['object'], r['subject']):f\"{r['relation_type']}-1\" for r in sent['relations']}\n",
    "    for ent_one, ent_two in combinations(sent['entities'].values(), r=2):\n",
    "        for e_one, e_two in [ent_one, ent_two], [ent_two, ent_one]:\n",
    "            combination_key = e_one['begin'], e_two['begin']\n",
    "            relation_type = rel_dict.get(combination_key, \"nil\")\n",
    "            subj_obj = e_one['label'], e_two['label']\n",
    "            if subj_obj in allowed_subj_obj:\n",
    "                sample = helper.build_relation_reprentation(sent, subj=e_one, obj=e_two, rel=relation_type)\n",
    "                yield sample\n",
    "    #return relation_representations\n",
    "sent = random.choice(sentence_entities_relations)\n",
    "relation_corpus = []\n",
    "for idx, sent in enumerate(sentence_entities_relations):\n",
    "    sent_samples = list(sent_to_relation_representations(sent, allowed_subj_obj))\n",
    "#     sent_samples = list(sent_to_relation_representations(sent))\n",
    "    for sent_sample, target in sent_samples:\n",
    "        relation_corpus.append((idx, sent_sample, target))\n",
    "len(sentence_entities_relations), len(relation_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb1e732",
   "metadata": {
    "id": "efb1e732"
   },
   "source": [
    "### Create a dataframe of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "450225c6-33e2-4502-8611-c7316f9c2abf",
   "metadata": {
    "id": "ee24d9dc"
   },
   "outputs": [],
   "source": [
    "sent_idx, X, y = zip(*relation_corpus)\n",
    "\n",
    "infos_dataset_df = pd.DataFrame(list(zip(sent_idx, X, y)), columns=['sentence_IDs', 'contexts', 'relations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73fcd33c-689b-4056-aa14-53cf9e8185ca",
   "metadata": {
    "id": "ee24d9dc"
   },
   "outputs": [],
   "source": [
    "infos_dataset_df['all_infos'] = infos_dataset_df.sentence_IDs.apply(lambda sent_idx: sentence_entities_relations[sent_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9b0cb38-693a-4d23-8224-d267ff09795c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "bbefdf6e",
    "outputId": "48d093a7-76b5-4091-c722-e846c3e3493a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5896, 4), 1091)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infos_dataset_df.shape, len(sentence_entities_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a60e28",
   "metadata": {
    "id": "02a60e28"
   },
   "source": [
    "#### Map each relation to label of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32daf1ae-a6ae-482e-9b3a-68ebf03a5ca5",
   "metadata": {
    "id": "bde729b8"
   },
   "outputs": [],
   "source": [
    "infos_dataset_df['labels'] = infos_dataset_df['relations'].apply(lambda row: relation_label_to_ID.get(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e083b1c6-95ee-44fb-b289-b3ad73f08bf7",
   "metadata": {
    "id": "bde729b8"
   },
   "outputs": [],
   "source": [
    "infos_dataset_df = infos_dataset_df.sample(len(infos_dataset_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02c62342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_IDs</th>\n",
       "      <th>contexts</th>\n",
       "      <th>relations</th>\n",
       "      <th>all_infos</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4371</th>\n",
       "      <td>807</td>\n",
       "      <td>Statistical analysis was performed using Excel...</td>\n",
       "      <td>Developer_of</td>\n",
       "      <td>{'sentence': 'Statistical analysis was perform...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>124</td>\n",
       "      <td>Ensembler is free and open source software lic...</td>\n",
       "      <td>nil</td>\n",
       "      <td>{'sentence': 'Ensembler is free and open sourc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>348</td>\n",
       "      <td>MRI and fMRI data were preprocessed by using F...</td>\n",
       "      <td>nil</td>\n",
       "      <td>{'sentence': 'MRI and fMRI data were preproces...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>709</td>\n",
       "      <td>All statistical analyses were done in Stata 12...</td>\n",
       "      <td>Developer_of</td>\n",
       "      <td>{'sentence': 'All statistical analyses were do...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>108</td>\n",
       "      <td>To compare the performance of SNPdetector with...</td>\n",
       "      <td>nil</td>\n",
       "      <td>{'sentence': 'To compare the performance of SN...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_IDs                                           contexts  \\\n",
       "4371           807  Statistical analysis was performed using Excel...   \n",
       "991            124  Ensembler is free and open source software lic...   \n",
       "1973           348  MRI and fMRI data were preprocessed by using F...   \n",
       "3944           709  All statistical analyses were done in Stata 12...   \n",
       "927            108  To compare the performance of SNPdetector with...   \n",
       "\n",
       "         relations                                          all_infos  labels  \n",
       "4371  Developer_of  {'sentence': 'Statistical analysis was perform...       1  \n",
       "991            nil  {'sentence': 'Ensembler is free and open sourc...       0  \n",
       "1973           nil  {'sentence': 'MRI and fMRI data were preproces...       0  \n",
       "3944  Developer_of  {'sentence': 'All statistical analyses were do...       1  \n",
       "927            nil  {'sentence': 'To compare the performance of SN...       0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infos_dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a96a2d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': '\" Project name : DelPhi Project home page : e.g. http://compbio.clemson.edu/delphi.php Operating system ( s ) : Linux , Mac , Windows Programming language : Fortran and C Other requirements : no License : free of charge license is required Any restrictions to use by non - academics : Commercial users should contact Accelrys Inc . \"',\n",
       " 'entities': {4: {'text': 'DelPhi',\n",
       "   'label': 'Application',\n",
       "   'intention': 'Deposition',\n",
       "   'begin': 4,\n",
       "   'end': 4},\n",
       "  10: {'text': 'http://compbio.clemson.edu/delphi.php',\n",
       "   'label': 'URL',\n",
       "   'intention': None,\n",
       "   'begin': 10,\n",
       "   'end': 10},\n",
       "  17: {'text': 'Linux',\n",
       "   'label': 'OperatingSystem',\n",
       "   'intention': 'Usage',\n",
       "   'begin': 17,\n",
       "   'end': 17},\n",
       "  19: {'text': 'Mac',\n",
       "   'label': 'OperatingSystem',\n",
       "   'intention': 'Usage',\n",
       "   'begin': 19,\n",
       "   'end': 19},\n",
       "  21: {'text': 'Windows',\n",
       "   'label': 'OperatingSystem',\n",
       "   'intention': 'Usage',\n",
       "   'begin': 21,\n",
       "   'end': 21},\n",
       "  25: {'text': 'Fortran',\n",
       "   'label': 'ProgrammingEnvironment',\n",
       "   'intention': 'Usage',\n",
       "   'begin': 25,\n",
       "   'end': 25},\n",
       "  27: {'text': 'C',\n",
       "   'label': 'ProgrammingEnvironment',\n",
       "   'intention': 'Usage',\n",
       "   'begin': 27,\n",
       "   'end': 27}},\n",
       " 'relations': [{'subject': 10, 'relation_type': 'URL_of', 'object': 4}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infos_dataset_df['all_infos'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf295682",
   "metadata": {
    "id": "bf295682"
   },
   "source": [
    "#### Split the dataset into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1341fe0f-d21b-40ea-8b0c-da09b281b5f6",
   "metadata": {
    "id": "W0DEbJkLg4Y6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, validation = train_test_split(infos_dataset_df, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4B7H7w9kg_mu",
   "metadata": {
    "id": "4B7H7w9kg_mu"
   },
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7505fb0d-a629-4f5e-a159-7cb9fba21d9c",
   "metadata": {
    "id": "qLMMHEk3g-jt"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, AutoTokenizer\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "204e0049-6065-4f84-bd1e-6ff0bdffd006",
   "metadata": {
    "id": "qLMMHEk3g-jt"
   },
   "outputs": [],
   "source": [
    "def prepare_sentence(sample):\n",
    "    text = sample.contexts\n",
    "    label = sample.labels\n",
    "    tokenized = tokenizer(text, truncation=True, padding=\"longest\", max_length=512)\n",
    "    tokenized[\"label\"] = sample.labels\n",
    "    return tokenized\n",
    "\n",
    "train_dataset = train.apply(prepare_sentence, axis=1).to_list()\n",
    "validation_dataset = validation.apply(prepare_sentence, axis=1).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a731dd8-80e7-4606-a5d5-42c9456f8b34",
   "metadata": {
    "id": "qLMMHEk3g-jt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4422, 1474)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134b0a4a",
   "metadata": {
    "id": "134b0a4a"
   },
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1080f552-57fd-4002-aee0-dc543a98f98f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16436d86",
    "outputId": "fcf60bce-9957-4fde-d9f9-c89397e99cf0"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "def compute_metrics(eval_preds, label_names):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    labels = [label_names[l] for l in labels]\n",
    "    predictions = pd.Series([label_names[p] for p in predictions])\n",
    "    n_predicted = predictions.value_counts().rename(\"n_predicted\")\n",
    "    metrics = precision_recall_fscore_support(labels, predictions, labels=label_names, zero_division=0)\n",
    "    metrics = pd.DataFrame(metrics, index=[\"prec\", \"recall\", \"f1\", \"support\"], columns=label_names).T\n",
    "    f = metrics.index != \"nil\"\n",
    "    metrics = metrics[f].copy()\n",
    "    ## weighted f1\n",
    "    weights = metrics.support / metrics.support.sum()\n",
    "    metrics = metrics.join(n_predicted)\n",
    "    metrics[\"n_predicted\"] = metrics.n_predicted.fillna(0)\n",
    "    metric_info = dict(\n",
    "        eval_f1_macro_weighted = (metrics.f1 * weights).sum(),\n",
    "        eval_support = metrics.support.sum(),\n",
    "        eval_n_predicted = metrics.n_predicted.fillna(0).sum()\n",
    "    )\n",
    "    for label, row in metrics.iterrows():\n",
    "        for metr, value in row.to_dict().items():\n",
    "            metric_info[f\"eval_{metr}_{label}\"] = value\n",
    "    return metric_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "394dd9ce-2232-4bb0-a316-61bb288ec80d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16436d86",
    "outputId": "fcf60bce-9957-4fde-d9f9-c89397e99cf0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nil',\n",
       " 'Developer_of',\n",
       " 'Abbreviation_of',\n",
       " 'URL_of',\n",
       " 'Citation_of',\n",
       " 'Release_of',\n",
       " 'Version_of',\n",
       " 'Specification_of',\n",
       " 'Extension_of',\n",
       " 'PlugIn_of',\n",
       " 'AlternativeName_of',\n",
       " 'License_of']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(relation_label_to_ID.keys())\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4606f099-1e19-409e-aeb9-e49acfb3933b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16436d86",
    "outputId": "fcf60bce-9957-4fde-d9f9-c89397e99cf0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fschr\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments, AutoModelForTokenClassification\n",
    "from transformers import BertForSequenceClassification\n",
    "from functools import partial\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./model_test',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=2,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=1e-5,\n",
    "    logging_dir='./logs',\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=100,\n",
    ")\n",
    "training_model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(labels))\n",
    "data_collator = DataCollatorWithPadding(tokenizer,\n",
    "                                        padding=\"longest\",\n",
    "                                        max_length=512)\n",
    "\n",
    "    \n",
    "    \n",
    "trainer = Trainer(\n",
    "    model=training_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset[:556],\n",
    "    eval_dataset=validation_dataset[:556], #validation_dataset\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=partial(compute_metrics, label_names=labels),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9d75ed2-bdf3-4f00-bfb5-7eb27dbadf65",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16436d86",
    "outputId": "fcf60bce-9957-4fde-d9f9-c89397e99cf0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='345' max='345' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [345/345 40:15, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1 Macro Weighted</th>\n",
       "      <th>Support</th>\n",
       "      <th>N Predicted</th>\n",
       "      <th>Prec Developer Of</th>\n",
       "      <th>Recall Developer Of</th>\n",
       "      <th>F1 Developer Of</th>\n",
       "      <th>Support Developer Of</th>\n",
       "      <th>N Predicted Developer Of</th>\n",
       "      <th>Prec Abbreviation Of</th>\n",
       "      <th>Recall Abbreviation Of</th>\n",
       "      <th>F1 Abbreviation Of</th>\n",
       "      <th>Support Abbreviation Of</th>\n",
       "      <th>N Predicted Abbreviation Of</th>\n",
       "      <th>Prec Url Of</th>\n",
       "      <th>Recall Url Of</th>\n",
       "      <th>F1 Url Of</th>\n",
       "      <th>Support Url Of</th>\n",
       "      <th>N Predicted Url Of</th>\n",
       "      <th>Prec Citation Of</th>\n",
       "      <th>Recall Citation Of</th>\n",
       "      <th>F1 Citation Of</th>\n",
       "      <th>Support Citation Of</th>\n",
       "      <th>N Predicted Citation Of</th>\n",
       "      <th>Prec Release Of</th>\n",
       "      <th>Recall Release Of</th>\n",
       "      <th>F1 Release Of</th>\n",
       "      <th>Support Release Of</th>\n",
       "      <th>N Predicted Release Of</th>\n",
       "      <th>Prec Version Of</th>\n",
       "      <th>Recall Version Of</th>\n",
       "      <th>F1 Version Of</th>\n",
       "      <th>Support Version Of</th>\n",
       "      <th>N Predicted Version Of</th>\n",
       "      <th>Prec Specification Of</th>\n",
       "      <th>Recall Specification Of</th>\n",
       "      <th>F1 Specification Of</th>\n",
       "      <th>Support Specification Of</th>\n",
       "      <th>N Predicted Specification Of</th>\n",
       "      <th>Prec Extension Of</th>\n",
       "      <th>Recall Extension Of</th>\n",
       "      <th>F1 Extension Of</th>\n",
       "      <th>Support Extension Of</th>\n",
       "      <th>N Predicted Extension Of</th>\n",
       "      <th>Prec Plugin Of</th>\n",
       "      <th>Recall Plugin Of</th>\n",
       "      <th>F1 Plugin Of</th>\n",
       "      <th>Support Plugin Of</th>\n",
       "      <th>N Predicted Plugin Of</th>\n",
       "      <th>Prec Alternativename Of</th>\n",
       "      <th>Recall Alternativename Of</th>\n",
       "      <th>F1 Alternativename Of</th>\n",
       "      <th>Support Alternativename Of</th>\n",
       "      <th>N Predicted Alternativename Of</th>\n",
       "      <th>Prec License Of</th>\n",
       "      <th>Recall License Of</th>\n",
       "      <th>F1 License Of</th>\n",
       "      <th>Support License Of</th>\n",
       "      <th>N Predicted License Of</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.107620</td>\n",
       "      <td>0.494179</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>0.891892</td>\n",
       "      <td>0.445946</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.672566</td>\n",
       "      <td>0.873563</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.920535</td>\n",
       "      <td>0.657005</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>271.000000</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.825806</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.582090</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.804598</td>\n",
       "      <td>0.765027</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.820807</td>\n",
       "      <td>0.631742</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>217.000000</td>\n",
       "      <td>0.791045</td>\n",
       "      <td>0.716216</td>\n",
       "      <td>0.751773</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.731429</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=345, training_loss=0.9497047313745471, metrics={'train_runtime': 2420.9547, 'train_samples_per_second': 1.148, 'train_steps_per_second': 0.143, 'total_flos': 166773937279680.0, 'train_loss': 0.9497047313745471, 'epoch': 4.9640287769784175})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f15e91f-e453-4e94-9d3a-23ca5e523be8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16436d86",
    "outputId": "fcf60bce-9957-4fde-d9f9-c89397e99cf0"
   },
   "outputs": [],
   "source": [
    "model_pred = BertForSequenceClassification.from_pretrained(\"model_test/checkpoint-345\")\n",
    "classifier = TextClassificationPipeline(model=model_pred,\n",
    "                                        tokenizer=tokenizer, device=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06280258-ed89-424a-b12b-03beca26457b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16436d86",
    "outputId": "fcf60bce-9957-4fde-d9f9-c89397e99cf0",
    "scrolled": true
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0992c6c",
   "metadata": {
    "id": "f0992c6c"
   },
   "source": [
    "### Read the test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "19665c77",
   "metadata": {
    "id": "19665c77"
   },
   "outputs": [],
   "source": [
    "# open the data of sentences\n",
    "with open('../../data/subtask3/subtask3_test.data.txt', 'r', encoding='utf-8') as file:\n",
    "    test_sentences = file.readlines()\n",
    "\n",
    "# open the entity labels\n",
    "with open('../../data/subtask3/subtask3_test.info.txt', 'r', encoding='utf-8') as file:\n",
    "    test_entity_labels = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6ccf3b9e",
   "metadata": {
    "id": "6ccf3b9e"
   },
   "outputs": [],
   "source": [
    "test_sentence_entities = []\n",
    "for idx, (sentence, entity_label_list) in enumerate(tuple(zip(test_sentences, test_entity_labels))):\n",
    "    token = sentence.split()\n",
    "    entity_bio_tags = entity_label_list.split()\n",
    "    ents = helper.get_entities(token, entity_bio_tags)\n",
    "    ent_dict = {e['begin']:e for e in ents}\n",
    "    sentence_info = dict(\n",
    "        sentence=sentence.strip(),\n",
    "        entities=ent_dict\n",
    "    )\n",
    "    test_sentence_entities.append(sentence_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a7abba7d",
   "metadata": {
    "id": "a7abba7d"
   },
   "outputs": [],
   "source": [
    "def sentence_subject_object(sent, allowed_subj_obj):\n",
    "    for ent_one, ent_two in combinations(sent['entities'].values(), r=2):\n",
    "            for e_one, e_two in [ent_one, ent_two], [ent_two, ent_one]:\n",
    "                subj_obj = e_one['label'], e_two['label']\n",
    "                if subj_obj in allowed_subj_obj:\n",
    "                    sample = helper.build_sentence_subj_obj(sent, subj=e_one, obj=e_two)\n",
    "                    yield sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4dfd591",
   "metadata": {
    "id": "e4dfd591",
    "outputId": "11f41a4f-3a0a-48f9-8a15-c94b1ead5dd9"
   },
   "outputs": [],
   "source": [
    "sentece_subj_obj_corpus = []\n",
    "for idx, sent in enumerate(test_sentence_entities):\n",
    "    sent_samples = list(sentence_subject_object(sent, allowed_subj_obj))\n",
    "    for sent_sample in sent_samples:\n",
    "        sentece_subj_obj_corpus.append((idx, sent_sample))\n",
    "# len(test_sentence_entities), len(sentece_subj_obj_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89d067f",
   "metadata": {
    "id": "a89d067f"
   },
   "source": [
    "### Create the dataframe for tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "adad8f2b",
   "metadata": {
    "id": "adad8f2b"
   },
   "outputs": [],
   "source": [
    "sent_idx, X = zip(*sentece_subj_obj_corpus)\n",
    "\n",
    "test_dataset_df = pd.DataFrame(list(zip(sent_idx, X)), columns=['sentence_IDs', 'contexts'])\n",
    "\n",
    "test_dataset_df['all_infos'] = test_dataset_df.apply(lambda row: [all_info\n",
    "                                                       for index, all_info in enumerate(test_sentence_entities)\n",
    "                                                       if row['sentence_IDs'] == index], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6da3df30",
   "metadata": {
    "id": "6da3df30",
    "outputId": "5a2658d9-cd0b-4bbf-b311-3f0d613d0d83"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_IDs</th>\n",
       "      <th>contexts</th>\n",
       "      <th>all_infos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The source code is available under the GNU GPL...</td>\n",
       "      <td>[{'sentence': 'The source code is available un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>The source code is available under the GNU GPL...</td>\n",
       "      <td>[{'sentence': 'The source code is available un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The source code is available under the GNU GPL...</td>\n",
       "      <td>[{'sentence': 'The source code is available un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>The source code is available under the GNU GPL...</td>\n",
       "      <td>[{'sentence': 'The source code is available un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>The source code is available under the GNU GPL...</td>\n",
       "      <td>[{'sentence': 'The source code is available un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>The source code is available under the GNU GPL...</td>\n",
       "      <td>[{'sentence': 'The source code is available un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>The source code is available under the GNU GPL...</td>\n",
       "      <td>[{'sentence': 'The source code is available un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>The source code is available under the GNU GPL...</td>\n",
       "      <td>[{'sentence': 'The source code is available un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>The source code is available under the GNU GPL...</td>\n",
       "      <td>[{'sentence': 'The source code is available un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>The source code is available under the GNU GPL...</td>\n",
       "      <td>[{'sentence': 'The source code is available un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>The source code is available under the GNU GPL...</td>\n",
       "      <td>[{'sentence': 'The source code is available un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>FIMTrack is freely available as a pre - built ...</td>\n",
       "      <td>[{'sentence': 'FIMTrack is freely available as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>The source code of FIMTrack is licensed under ...</td>\n",
       "      <td>[{'sentence': 'The source code of FIMTrack is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>The source code of FIMTrack is licensed under ...</td>\n",
       "      <td>[{'sentence': 'The source code of FIMTrack is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>The source code of FIMTrack is licensed under ...</td>\n",
       "      <td>[{'sentence': 'The source code of FIMTrack is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>The source code of FIMTrack is licensed under ...</td>\n",
       "      <td>[{'sentence': 'The source code of FIMTrack is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>The source code of FIMTrack is licensed under ...</td>\n",
       "      <td>[{'sentence': 'The source code of FIMTrack is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>At present Chaste can only be used with Linux ...</td>\n",
       "      <td>[{'sentence': 'At present Chaste can only be u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3</td>\n",
       "      <td>At present Chaste can only be used with Linux ...</td>\n",
       "      <td>[{'sentence': 'At present Chaste can only be u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>At present Chaste can only be used with Linux ...</td>\n",
       "      <td>[{'sentence': 'At present Chaste can only be u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentence_IDs                                           contexts  \\\n",
       "0              0  The source code is available under the GNU GPL...   \n",
       "1              0  The source code is available under the GNU GPL...   \n",
       "2              0  The source code is available under the GNU GPL...   \n",
       "3              0  The source code is available under the GNU GPL...   \n",
       "4              0  The source code is available under the GNU GPL...   \n",
       "5              0  The source code is available under the GNU GPL...   \n",
       "6              0  The source code is available under the GNU GPL...   \n",
       "7              0  The source code is available under the GNU GPL...   \n",
       "8              0  The source code is available under the GNU GPL...   \n",
       "9              0  The source code is available under the GNU GPL...   \n",
       "10             0  The source code is available under the GNU GPL...   \n",
       "11             1  FIMTrack is freely available as a pre - built ...   \n",
       "12             2  The source code of FIMTrack is licensed under ...   \n",
       "13             2  The source code of FIMTrack is licensed under ...   \n",
       "14             2  The source code of FIMTrack is licensed under ...   \n",
       "15             2  The source code of FIMTrack is licensed under ...   \n",
       "16             2  The source code of FIMTrack is licensed under ...   \n",
       "17             3  At present Chaste can only be used with Linux ...   \n",
       "18             3  At present Chaste can only be used with Linux ...   \n",
       "19             3  At present Chaste can only be used with Linux ...   \n",
       "\n",
       "                                            all_infos  \n",
       "0   [{'sentence': 'The source code is available un...  \n",
       "1   [{'sentence': 'The source code is available un...  \n",
       "2   [{'sentence': 'The source code is available un...  \n",
       "3   [{'sentence': 'The source code is available un...  \n",
       "4   [{'sentence': 'The source code is available un...  \n",
       "5   [{'sentence': 'The source code is available un...  \n",
       "6   [{'sentence': 'The source code is available un...  \n",
       "7   [{'sentence': 'The source code is available un...  \n",
       "8   [{'sentence': 'The source code is available un...  \n",
       "9   [{'sentence': 'The source code is available un...  \n",
       "10  [{'sentence': 'The source code is available un...  \n",
       "11  [{'sentence': 'FIMTrack is freely available as...  \n",
       "12  [{'sentence': 'The source code of FIMTrack is ...  \n",
       "13  [{'sentence': 'The source code of FIMTrack is ...  \n",
       "14  [{'sentence': 'The source code of FIMTrack is ...  \n",
       "15  [{'sentence': 'The source code of FIMTrack is ...  \n",
       "16  [{'sentence': 'The source code of FIMTrack is ...  \n",
       "17  [{'sentence': 'At present Chaste can only be u...  \n",
       "18  [{'sentence': 'At present Chaste can only be u...  \n",
       "19  [{'sentence': 'At present Chaste can only be u...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985fb1e2",
   "metadata": {
    "id": "ef87aafa"
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fdab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrected version\n",
    "n_expected_sentences = test_dataset_df.sentence_IDs.max() + 1\n",
    "previous_sentence_id = None\n",
    "sentence_predictions = [\"\" for _ in range(n_expected_sentences)]\n",
    "current_relations = []\n",
    "for index, row in test_dataset_df.iterrows():\n",
    "    current_sentence_id = row['sentence_IDs']\n",
    "    # Check if we have moved to a new sentence\n",
    "    if current_sentence_id != previous_sentence_id and previous_sentence_id is not None:\n",
    "        # Append the formatted line for the previous sentence\n",
    "        sentence_predictions[previous_sentence_id] = \";\".join(current_relations)\n",
    "        current_relations = []\n",
    " \n",
    "    # Predict the label using the classifier\n",
    "    predict = classifier(row['contexts'])\n",
    "    label = ID_to_relation_label.get(int(predict[0]['label'].split('_')[-1]))\n",
    "    # skip the nil labels\n",
    " \n",
    "    # Split the contexts and process each entity\n",
    "    # E.g. \"satz python [34, 13] [SEP] [Reference: '[34, 13]'], [Enironment: 'python']\"\n",
    "    subj_info, object_info = row['contexts'].split('[SEP] [')[-1].split(\"'], [\")\n",
    "    subj_label, subj_text = subj_info.split(\": '\")\n",
    "    obj_label, obj_text = object_info[:-2].split(\": '\")\n",
    "    entities = row[\"all_infos\"][0][\"entities\"]\n",
    "    for ent_begin, ent in entities.items():\n",
    "        if ent['label'] == subj_label and ent['text'] == subj_text:\n",
    "            subj_begin = ent[\"begin\"]\n",
    "        if ent['label'] == obj_label and ent['text'] == obj_text:\n",
    "            obj_begin = ent[\"begin\"]\n",
    "    relation_repr = f\"{label}\\t{subj_begin}\\t{obj_begin}\"\n",
    "    if label != \"nil\":\n",
    "        current_relations.append(relation_repr)\n",
    "    previous_sentence_id = current_sentence_id\n",
    " \n",
    "# Ensure the last set is appended\n",
    "sentence_predictions[previous_sentence_id] = \";\".join(current_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ff78d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../data/subtask3/prediction/prediction_dataset.txt', 'w') as file:\n",
    "  for prediction in all_predicted_text_classification_dataset:\n",
    "    file.write(f'{prediction}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bb7a94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
